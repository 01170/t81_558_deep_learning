{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 5: Regularization and Dropout**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Video Material\n",
    "\n",
    "Main video lecture:\n",
    "\n",
    "* [Part 5.1: Part 5.1: Introduction to Regularization: Ridge and Lasso](https://www.youtube.com/watch?v=9abzk34U56c&index=15&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 5.2: Using K-Fold Cross Validation with Keras](https://www.youtube.com/watch?v=GkKTWSInNvA&index=16&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting](https://www.youtube.com/watch?v=uLa-b3JxWAM&index=17&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 5.4: Drop Out for Keras to Decrease Overfitting](https://www.youtube.com/watch?v=uLa-b3JxWAM&index=17&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 5.5: Benchmarking Keras Deep Learning Regularization Techniques](https://www.youtube.com/watch?v=uLa-b3JxWAM&index=17&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.1: Introduction to Regularization: Ridge and Lasso\n",
    "\n",
    "We are going to look at linear regression to see how L1 and L2 regularization work.  The following code sets up the auto-mpg data for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Handle missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "names = ['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']\n",
    "x = df[names].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a regression\n",
    "%matplotlib inline    \n",
    "from IPython.display import display, HTML    \n",
    "\n",
    "def report_coef(names,coef,intercept):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    print(f\"Intercept: {intercept}\")\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "To understand L1/L2 regularization, it is good to start with linear regression.  L1/L2 were first introduced for [linear regression](https://en.wikipedia.org/wiki/Linear_regression).  They can also be used for neural networks.  To fully understand L1/L2 we will begin with how they are used with linear regression.\n",
    "\n",
    "The following code uses linear regression to fit the auto-mpg data set.  The RMSE reported will not be as good as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.0019345985860784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.427721</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.005491</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.020166</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.138575</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.783047</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>1.003762</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "cylinders    -0.427721     False\n",
       "weight       -0.007255     False\n",
       "horsepower   -0.005491     False\n",
       "displacement  0.020166      True\n",
       "acceleration  0.138575      True\n",
       "year          0.783047      True\n",
       "origin        1.003762      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -19.101231042200112\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Create linear regression\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"Final score (RMSE): {score}\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (Lasso) Regularization\n",
    "\n",
    "L1 Regularization, also called LASSO (Least Absolute Shrinkage and Selection Operator) is should be used to create sparsity in the neural network. In other words, the L1 algorithm will push many weight connections to near 0.  When a weight is near 0, the program drops it from the network.  Dropping weighted connections will create a sparse neural network.\n",
    "\n",
    "Feature selection is a useful byproduct of sparse neural networks. Features are the values that the training set provides to the input neurons.  Once all the weights of an input neuron reach 0, the neural network training determines that the feature is unnecessary.  If your data set has a large number of input features that may not be needed, L1 regularization can help the neural network detect and ignore unnecessary features.\n",
    "\n",
    "L1 is implemented by adding the following error to the objective to minimize:\n",
    "\n",
    "$$ E_1 = \\alpha \\sum_w{ |w| } $$\n",
    "\n",
    "The following code demonstrates lasso regression.  Notice the effect of the coefficients compared to the previous section that used linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.060402190403331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.012995</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007328</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.002715</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.011601</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.114391</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0.708222</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.777480</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "cylinders    -0.012995     False\n",
       "weight       -0.007328     False\n",
       "horsepower   -0.002715     False\n",
       "displacement  0.011601      True\n",
       "acceleration  0.114391      True\n",
       "origin        0.708222      True\n",
       "year          0.777480      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -18.50667798238321\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Lasso(random_state=0,alpha=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"Final score (RMSE): {score}\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-08, 100000000.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-8, 8, 10)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    this_scores = cross_val_score(lasso, x, y, cv=n_folds, n_jobs=1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "\n",
    "scores, scores_std = np.array(scores), np.array(scores_std)\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (Ridge) Regularization\n",
    "\n",
    "You should use Tikhonov/Ridge/L2 regularization when you are less concerned about creating a space network and are more concerned about low weight values.  The lower weight values will typically lead to less overfitting. \n",
    "\n",
    "$$ E_2 = \\alpha \\sum_w{ w^2 } $$\n",
    "\n",
    "Like the L1 algorithm, the $\\alpha$ value determines how important the L2 objective is compared to the neural network’s error.  Typical L2 values are below 0.1 (10%).  The main calculation performed by L2 is the summing of the squares of all of the weights.  The bias values are not summed.\n",
    "\n",
    "The following code uses L2 with linear regression (Ridge regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): {score}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.421393</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007257</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.005385</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.020006</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.138470</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.782889</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0.994621</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "cylinders    -0.421393     False\n",
       "weight       -0.007257     False\n",
       "horsepower   -0.005385     False\n",
       "displacement  0.020006      True\n",
       "acceleration  0.138470      True\n",
       "year          0.782889      True\n",
       "origin        0.994621      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -19.07980074425469\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Ridge(alpha=1)\n",
    "\n",
    "# Fit/train Ridge\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {score}\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regularization\n",
    "\n",
    "The ElasticNet regression combines both L1 and L2.  Both penalties are applied.  The amount of L1 and L2 are governed by the parameters alpha and beta.\n",
    "\n",
    "$$\n",
    "a * L1 + b * L2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.045089996077502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.274010</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007303</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.003231</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.016194</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.132348</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.777482</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>0.782781</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "cylinders    -0.274010     False\n",
       "weight       -0.007303     False\n",
       "horsepower   -0.003231     False\n",
       "displacement  0.016194      True\n",
       "acceleration  0.132348      True\n",
       "year          0.777482      True\n",
       "origin        0.782781      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -18.38935569042974\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create linear regression\n",
    "regressor = ElasticNet(alpha=0.1, l1_ratio=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"Final score (RMSE): {score}\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.2: Using K-Fold Cross Validation with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation uses a number of folds, and multiple models, to generate out of sample predictions on the entire dataset.  It is important to note that there will be one model (neural network) for each fold. Each model contributes part of the final out-of-sample prediction.\n",
    "\n",
    "![K-Fold Crossvalidation](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_1_kfold.png \"K-Fold Crossvalidation\")\n",
    "\n",
    "For new data, which is data not present in the training set, predictions from the fold models can be handled in several ways.\n",
    "\n",
    "* Choose the model that had the highest validation score as the final model.\n",
    "* Preset new data to the 5 models and average the result (this is an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning)).\n",
    "* Retrain a new model (using the same settings as the cross-validation) on the entire dataset.  Train for as many epochs, and with the same hidden layer structure.\n",
    "\n",
    "## Regression with K-Fold Cross-Validation\n",
    "\n",
    "The following code trains the MPG dataset using a 5-fold cross-validation.  The expected performance of a neural network, of the type trained here, would be the score for the generated out-of-sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "Fold score (RMSE): 0.7465897155896363, epochs needed 136\n",
      "Fold #2\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00142: early stopping\n",
      "Fold score (RMSE): 0.6236349426949113, epochs needed 141\n",
      "Fold #3\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00134: early stopping\n",
      "Fold score (RMSE): 0.8543803433697185, epochs needed 133\n",
      "Fold #4\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00145: early stopping\n",
      "Fold score (RMSE): 0.6874962044212919, epochs needed 144\n",
      "Fold #5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "Fold score (RMSE): 1.0345504516785673, epochs needed 116\n",
      "Average number of epochs needed: 134\n",
      "Final, out of sample score (RMSE): 0.802399923289237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cross-Validate\n",
    "kf = KFold(5, shuffle=True, random_state=42) # Use for KFold classification\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "epochs_needed = []\n",
    "\n",
    "fold = 0\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)    \n",
    "    epochs = monitor.stopped_epoch\n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}, epochs needed {epochs}\")\n",
    "    epochs_needed.append(epochs)\n",
    "\n",
    "print(f\"Average number of epochs needed: {round(sum(epochs_needed)/len(epochs_needed))}\")\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(f\"Final, out of sample score (RMSE): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv(filename_write,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the above code also reports the average number of epochs needed.  A common technique is to then train on the entire dataset for the average number of epochs needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Stratified K-Fold Cross-Validation\n",
    "\n",
    "The following code trains and fits the iris dataset with Cross-Validation.  It also writes out the out of sample (predictions on the test set) results.\n",
    "\n",
    "It is good to perform a stratified k-fold cross validation with classification data.  This ensures that the percentages of each class remains the same across all folds.  To do this, make use of the **StratifiedKFold** object, instead of the **KFold** object used in regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "Fold score (accuracy): 0.746268656716418, epochs needed 81\n",
      "Fold #2\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "Fold score (accuracy): 0.6890547263681592, epochs needed 78\n",
      "Fold #3\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "Fold score (accuracy): 0.71571072319202, epochs needed 51\n",
      "Fold #4\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00064: early stopping\n",
      "Fold score (accuracy): 0.6934673366834171, epochs needed 63\n",
      "Fold #5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "Fold score (accuracy): 0.7178841309823678, epochs needed 60\n",
      "Final score (accuracy): 0.7125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# np.argmax(pred,axis=1)\n",
    "# Cross-validate\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42) # Use for StratifiedKFold classification\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "epochs_needed = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x,df['product']): # Must specify y StratifiedKFold for \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=25, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)  \n",
    "    epochs = monitor.stopped_epoch\n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}, epochs needed {epochs}\")\n",
    "    epochs_needed.append(epochs)\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv(filename_write,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with both a Cross-Validation and a Holdout Set\n",
    "\n",
    "If you have a considerable amount of data, it is always valuable to set aside a holdout set before you cross-validate.  This hold out set will be the final evaluation before you make use of your model for its real-world use.\n",
    "\n",
    "![Cross Validation and a Holdout Set](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_3_hold_train_val.png \"Cross Validation and a Holdout Set\")\n",
    "\n",
    "The following program makes use of a holdout set, and then still cross-validates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00126: early stopping\n",
      "Fold score (RMSE): 0.8277214937220675\n",
      "Fold #2\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00187: early stopping\n",
      "Fold score (RMSE): 0.8358278146230218\n",
      "Fold #3\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00173: early stopping\n",
      "Fold score (RMSE): 0.6928553150793878\n",
      "Fold #4\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00136: early stopping\n",
      "Fold score (RMSE): 0.6748407416330722\n",
      "Fold #5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00130: early stopping\n",
      "Fold score (RMSE): 1.086916893238514\n",
      "\n",
      "Cross-validated score (RMSE): 0.8367290904320087\n",
      "Holdout score (RMSE): 0.8411745024788277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Keep a 10% holdout\n",
    "x_main, x_holdout, y_main, y_holdout = train_test_split(    \n",
    "    x, y, test_size=0.10) \n",
    "\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x_main):        \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x_main[train]\n",
    "    y_train = y_main[train]\n",
    "    x_test = x_main[test]\n",
    "    y_test = y_main[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "            patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred) \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}\")\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print()\n",
    "print(f\"Cross-validated score (RMSE): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction (from the last neural network)\n",
    "holdout_pred = model.predict(x_holdout)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(holdout_pred,y_holdout))\n",
    "print(f\"Holdout score (RMSE): {score}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 and L2 regularization are two common regularization techniques that can reduce the effects of overfitting (Ng, 2004).  Both of these algorithms can either work with an objective function or as a part of the backpropagation algorithm.  In both cases the regularization algorithm is attached to the training algorithm by adding an additional objective.  \n",
    "\n",
    "Both of these algorithms work by adding a weight penalty to the neural network training.  This penalty encourages the neural network to keep the weights to small values.  Both L1 and L2 calculate this penalty differently.  For gradient-descent-based algorithms, such as backpropagation, you can add this penalty calculation to the calculated gradients.  For objective-function-based training, such as simulated annealing, the penalty is negatively combined with the objective score.\n",
    "\n",
    "Both L1 and L2 work differently in the way that they penalize the size of a weight.  L2 will force the weights into a pattern similar to a Gaussian distribution; the L1 will force the weights into a pattern similar to a Laplace distribution, as demonstrated the following:\n",
    "\n",
    "![L1 vs L2](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_9_l1_l2.png \"L1 vs L2\")\n",
    "\n",
    "As you can see, L1 algorithm is more tolerant of weights further from 0, whereas the L2 algorithm is less tolerant.  We will highlight other important differences between L1 and L2 in the following sections.  You also need to note that both L1 and L2 count their penalties based only on weights; they do not count penalties on bias values.\n",
    "\n",
    "Tensor flow allows [l1/l2 to be directly added to your network](http://tensorlayer.readthedocs.io/en/stable/modules/cost.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00056: early stopping\n",
      "Fold score (accuracy): 0.6975\n",
      "Fold #2\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "Fold score (accuracy): 0.7425\n",
      "Fold #3\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00051: early stopping\n",
      "Fold score (accuracy): 0.71\n",
      "Fold #4\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00083: early stopping\n",
      "Fold score (accuracy): 0.7125\n",
      "Fold #5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00049: early stopping\n",
      "Fold score (accuracy): 0.695\n",
      "Final score (accuracy): 0.7115\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Keras with L1/L2 for Regression\n",
    "########################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    #kernel_regularizer=regularizers.l2(0.01),\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], \n",
    "            activation='relu',\n",
    "             activity_regularizer=regularizers.l1(1e-4))) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu', \n",
    "                    activity_regularizer=regularizers.l1(1e-4))) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "            patience=25, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv(filename_write,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.4: Drop Out for Keras to Decrease Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Srivastava, N., Hinton, G. E., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). [Dropout: a simple way to prevent neural networks from overfitting.](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) *Journal of Machine Learning Research*, 15(1), 1929-1958.\n",
    "\n",
    "Most neural network frameworks implement dropout as a separate layer.  Dropout layers function as a regular, densely connected neural network layer.  The only difference is that the dropout layers will periodically drop some of their neurons during training.  You can use dropout layers on regular feedforward neural networks. In fact, they can also become layers in convolutional LeNET-5 networks like we studied in class 8.\n",
    "\n",
    "The usual hyper-parameters for a dropout layer are the following:\n",
    "* Neuron Count\n",
    "* Activation Function\n",
    "* Dropout Probability\n",
    "\n",
    "The neuron count and activation function hyper-parameters work exactly the same way as their corresponding parameters in the dense layer type mentioned previously. The neuron count simply specifies the number of neurons in the dropout layer.  The dropout probability indicates the likelihood of a neuron dropping out during the training iteration.  Just as it does for a dense layer, the program specifies an activation function for the dropout layer.\n",
    "\n",
    "![Dropout Regularization](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_9_dropout.png \"Dropout Regularization\")\n",
    "\n",
    "A certain percentage of neurons will be masked during each training step.  All neurons return after training is complete.  To make use of dropout in Keras use the **Dropout** layer and specify a dropout probability.  This is the percent of neurons to be dropped.  Typically, this is a low value, such as 0.1.\n",
    "\n",
    "Animation that shows how [dropout works](https://yusugomori.com/projects/deep-learning/dropout-relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_median' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7ad98fbd59c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmissing_median\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horsepower'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Split into train/test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'missing_median' is not defined"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# TensorFlow with Dropout for Regression\n",
    "############################################\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df, 'horsepower')\n",
    "x,y = to_xy(df,\"mpg\")\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1]))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "pred = model.predict(x_test)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.5: Benchmarking Keras Deep Learning Regularization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap #1: score=0.7447948920113355, mean score=0.7447948920113355, epochs=104, time=0:00:05.77\n",
      "Bootstrap #2: score=0.8680367473891414, mean score=0.8064158197002385, epochs=119, time=0:00:06.12\n",
      "Bootstrap #3: score=0.7820547846592762, mean score=0.7982954746865843, epochs=99, time=0:00:05.17\n",
      "Bootstrap #4: score=0.5670574259730553, mean score=0.7404859625082021, epochs=144, time=0:00:07.39\n",
      "Bootstrap #5: score=0.5920759728764031, mean score=0.7108039645818423, epochs=120, time=0:00:06.58\n",
      "Bootstrap #6: score=0.8802537973831938, mean score=0.7390456033820675, epochs=127, time=0:00:07.60\n",
      "Bootstrap #7: score=0.561739570929457, mean score=0.7137161701745517, epochs=116, time=0:00:06.10\n",
      "Bootstrap #8: score=0.5101354448176023, mean score=0.688268579504933, epochs=156, time=0:00:08.59\n",
      "Bootstrap #9: score=0.6945224576729497, mean score=0.6889634548569349, epochs=146, time=0:00:07.79\n",
      "Bootstrap #10: score=1.1181064460075167, mean score=0.731877753971993, epochs=144, time=0:00:07.39\n",
      "Bootstrap #11: score=1.1769181263466861, mean score=0.7723359696424197, epochs=90, time=0:00:04.77\n",
      "Bootstrap #12: score=0.7145344741920572, mean score=0.7675191783548895, epochs=132, time=0:00:06.80\n",
      "Bootstrap #13: score=0.6639751017837054, mean score=0.7595542493878753, epochs=94, time=0:00:05.12\n",
      "Bootstrap #14: score=1.1989759922087277, mean score=0.7909415167322219, epochs=81, time=0:00:04.40\n",
      "Bootstrap #15: score=0.6201058940328992, mean score=0.7795524752189338, epochs=105, time=0:00:07.16\n",
      "Bootstrap #16: score=0.672540671457096, mean score=0.7728642374838189, epochs=118, time=0:00:06.83\n",
      "Bootstrap #17: score=0.8143095663039669, mean score=0.7753021980026512, epochs=82, time=0:00:04.94\n",
      "Bootstrap #18: score=0.8043661722971385, mean score=0.7769168632412338, epochs=118, time=0:00:06.39\n",
      "Bootstrap #19: score=0.8933899863418034, mean score=0.783047027614948, epochs=137, time=0:00:07.18\n",
      "Bootstrap #20: score=0.8253426476378161, mean score=0.7851618086160914, epochs=100, time=0:00:05.88\n",
      "Bootstrap #21: score=0.7742619070915447, mean score=0.784642765686351, epochs=92, time=0:00:06.47\n",
      "Bootstrap #22: score=0.5529573431289493, mean score=0.7741116101155601, epochs=105, time=0:00:05.77\n",
      "Bootstrap #23: score=0.7562712755580911, mean score=0.7733359433956701, epochs=103, time=0:00:05.78\n",
      "Bootstrap #24: score=0.63416491216135, mean score=0.7675371504275734, epochs=116, time=0:00:06.22\n",
      "Bootstrap #25: score=0.6882905041072704, mean score=0.7643672845747613, epochs=108, time=0:00:05.74\n",
      "Bootstrap #26: score=0.7205404155018369, mean score=0.7626816357642643, epochs=104, time=0:00:05.49\n",
      "Bootstrap #27: score=0.7774991960159855, mean score=0.7632304342921058, epochs=101, time=0:00:05.33\n",
      "Bootstrap #28: score=0.9116824064911876, mean score=0.7685322904420729, epochs=111, time=0:00:05.90\n",
      "Bootstrap #29: score=0.553852225255622, mean score=0.7611295295735746, epochs=95, time=0:00:05.71\n",
      "Bootstrap #30: score=0.5766622245612161, mean score=0.754980619406496, epochs=120, time=0:00:07.30\n",
      "Bootstrap #31: score=0.6846253108204653, mean score=0.7527110933230756, epochs=115, time=0:00:06.13\n",
      "Bootstrap #32: score=0.6097363534509307, mean score=0.7482431327020711, epochs=116, time=0:00:06.07\n",
      "Bootstrap #33: score=0.7910136501045136, mean score=0.7495392089869936, epochs=120, time=0:00:06.35\n",
      "Bootstrap #34: score=1.1428692174733972, mean score=0.7611077386483585, epochs=112, time=0:00:05.95\n",
      "Bootstrap #35: score=0.5801248265848041, mean score=0.7559367983036854, epochs=152, time=0:00:07.79\n",
      "Bootstrap #36: score=0.8185163611840601, mean score=0.7576751194948069, epochs=107, time=0:00:05.62\n",
      "Bootstrap #37: score=0.9219578059205334, mean score=0.7621151921009076, epochs=107, time=0:00:05.71\n",
      "Bootstrap #38: score=0.6558777743203714, mean score=0.7593194705803672, epochs=133, time=0:00:06.81\n",
      "Bootstrap #39: score=0.624911394883268, mean score=0.7558731096650569, epochs=100, time=0:00:05.24\n",
      "Bootstrap #40: score=0.6917359815527345, mean score=0.7542696814622489, epochs=100, time=0:00:05.62\n",
      "Bootstrap #41: score=1.2462372553973895, mean score=0.7662688905826182, epochs=82, time=0:00:04.50\n",
      "Bootstrap #42: score=0.5931370501810701, mean score=0.7621467039063907, epochs=110, time=0:00:05.85\n",
      "Bootstrap #43: score=0.6389037628092409, mean score=0.7592805889971548, epochs=95, time=0:00:05.78\n",
      "Bootstrap #44: score=0.571696370310097, mean score=0.7550173112997217, epochs=124, time=0:00:06.86\n",
      "Bootstrap #45: score=0.9673674386084755, mean score=0.7597362030176941, epochs=101, time=0:00:05.87\n",
      "Bootstrap #46: score=0.6678253389593406, mean score=0.7577381407555559, epochs=105, time=0:00:06.02\n",
      "Bootstrap #47: score=0.5749140265332474, mean score=0.7538482659848685, epochs=140, time=0:00:07.64\n",
      "Bootstrap #48: score=0.529949496208682, mean score=0.749183708281198, epochs=115, time=0:00:06.32\n",
      "Bootstrap #49: score=0.9149734656143265, mean score=0.7525671727165678, epochs=127, time=0:00:06.77\n",
      "Bootstrap #50: score=0.6609209976255579, mean score=0.7507342492147476, epochs=122, time=0:00:06.44\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "SPLITS = 50\n",
    "\n",
    "# Bootstrap\n",
    "boot = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
    "\n",
    "# Track progress\n",
    "mean_benchmark = []\n",
    "num = 0\n",
    "\n",
    "# Loop through samples\n",
    "for train, test in boot.split(x):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Split train and test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construct neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train on the bootstrap sample\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    \n",
    "    # Predict on the out of boot (validation)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # Measure this bootstrap's log loss\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    mean_benchmark.append(score)\n",
    "    m = sum(mean_benchmark)/len(mean_benchmark)\n",
    "    \n",
    "    # Record this iteration\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"Bootstrap #{num}: RMSE Score={score}, mean score={m}, epochs={epochs}, time={hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SPLITS = 50\n",
    "\n",
    "# Bootstrap\n",
    "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
    "\n",
    "# Track progress\n",
    "mean_benchmark = []\n",
    "num = 0\n",
    "\n",
    "# Loop through samples\n",
    "for train, test in boot.split(x,df['product']):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Split train and test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construct neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=25, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train on the bootstrap sample\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    \n",
    "    # Predict on the out of boot (validation)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # Measure this bootstrap's log loss\n",
    "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
    "    score = metrics.log_loss(y_compare, pred)\n",
    "    mean_benchmark.append(score)\n",
    "    m = sum(mean_benchmark)/len(mean_benchmark)\n",
    "    \n",
    "    # Record this iteration\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"Bootstrap #{num}: Log Loss Sore={score}, mean score={m}, epochs={epochs}, time={hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap #1: Log Loss score=0.627267, mean score=0.627267, stdev=0.000000 epochs=314, time=0:00:26.09\n",
      "Bootstrap #2: Log Loss score=0.763436, mean score=0.695352, stdev=0.068085 epochs=138, time=0:00:12.73\n",
      "Bootstrap #3: Log Loss score=0.655261, mean score=0.681988, stdev=0.058716 epochs=163, time=0:00:14.59\n",
      "Bootstrap #4: Log Loss score=0.733282, mean score=0.694812, stdev=0.055488 epochs=186, time=0:00:17.00\n",
      "Bootstrap #5: Log Loss score=0.695168, mean score=0.694883, stdev=0.049631 epochs=171, time=0:00:21.24\n",
      "Bootstrap #6: Log Loss score=0.672425, mean score=0.691140, stdev=0.046073 epochs=214, time=0:00:27.14\n",
      "Bootstrap #7: Log Loss score=0.692991, mean score=0.691404, stdev=0.042660 epochs=302, time=0:00:38.87\n",
      "Bootstrap #8: Log Loss score=0.688647, mean score=0.691060, stdev=0.039915 epochs=249, time=0:00:23.80\n",
      "Bootstrap #9: Log Loss score=0.726430, mean score=0.694990, stdev=0.039240 epochs=169, time=0:00:15.50\n",
      "Bootstrap #10: Log Loss score=0.638404, mean score=0.689331, stdev=0.040914 epochs=232, time=0:00:20.06\n",
      "Bootstrap #11: Log Loss score=0.622275, mean score=0.683235, stdev=0.043513 epochs=218, time=0:00:20.80\n",
      "Bootstrap #12: Log Loss score=0.641122, mean score=0.679726, stdev=0.043256 epochs=329, time=0:00:27.95\n",
      "Bootstrap #13: Log Loss score=0.594357, mean score=0.673159, stdev=0.047378 epochs=383, time=0:00:33.77\n",
      "Bootstrap #14: Log Loss score=0.609400, mean score=0.668605, stdev=0.048517 epochs=442, time=0:00:37.66\n",
      "Bootstrap #15: Log Loss score=0.629727, mean score=0.666013, stdev=0.047865 epochs=190, time=0:00:16.50\n",
      "Bootstrap #16: Log Loss score=0.678096, mean score=0.666768, stdev=0.046437 epochs=240, time=0:00:20.23\n",
      "Bootstrap #17: Log Loss score=0.673941, mean score=0.667190, stdev=0.045082 epochs=229, time=0:00:19.11\n",
      "Bootstrap #18: Log Loss score=0.707283, mean score=0.669417, stdev=0.044764 epochs=203, time=0:00:20.09\n",
      "Bootstrap #19: Log Loss score=0.707733, mean score=0.671434, stdev=0.044403 epochs=273, time=0:00:25.49\n",
      "Bootstrap #20: Log Loss score=0.701967, mean score=0.672961, stdev=0.043787 epochs=213, time=0:00:20.78\n",
      "Bootstrap #21: Log Loss score=0.624734, mean score=0.670664, stdev=0.043949 epochs=348, time=0:00:32.53\n",
      "Bootstrap #22: Log Loss score=0.749800, mean score=0.674261, stdev=0.045993 epochs=153, time=0:00:13.54\n",
      "Bootstrap #23: Log Loss score=0.747155, mean score=0.677431, stdev=0.047375 epochs=229, time=0:00:18.89\n",
      "Bootstrap #24: Log Loss score=0.706375, mean score=0.678637, stdev=0.046737 epochs=184, time=0:00:15.40\n",
      "Bootstrap #25: Log Loss score=0.618672, mean score=0.676238, stdev=0.047276 epochs=300, time=0:00:24.77\n",
      "Bootstrap #26: Log Loss score=0.557668, mean score=0.671678, stdev=0.051662 epochs=499, time=0:00:39.38\n",
      "Bootstrap #27: Log Loss score=0.666463, mean score=0.671484, stdev=0.050706 epochs=242, time=0:00:24.24\n",
      "Bootstrap #28: Log Loss score=0.654411, mean score=0.670875, stdev=0.049893 epochs=257, time=0:00:26.29\n",
      "Bootstrap #29: Log Loss score=0.549884, mean score=0.666703, stdev=0.053767 epochs=372, time=0:00:31.35\n",
      "Bootstrap #30: Log Loss score=0.624993, mean score=0.665312, stdev=0.053391 epochs=254, time=0:00:21.06\n",
      "Bootstrap #31: Log Loss score=0.674483, mean score=0.665608, stdev=0.052548 epochs=216, time=0:00:18.12\n",
      "Bootstrap #32: Log Loss score=0.582296, mean score=0.663005, stdev=0.053713 epochs=280, time=0:00:23.33\n",
      "Bootstrap #33: Log Loss score=0.647942, mean score=0.662548, stdev=0.052956 epochs=296, time=0:00:25.85\n",
      "Bootstrap #34: Log Loss score=0.693059, mean score=0.663446, stdev=0.052425 epochs=209, time=0:00:17.84\n",
      "Bootstrap #35: Log Loss score=0.724318, mean score=0.665185, stdev=0.052657 epochs=184, time=0:00:16.73\n",
      "Bootstrap #36: Log Loss score=0.606983, mean score=0.663568, stdev=0.052794 epochs=331, time=0:00:34.97\n",
      "Bootstrap #37: Log Loss score=0.650002, mean score=0.663201, stdev=0.052122 epochs=204, time=0:00:20.31\n",
      "Bootstrap #38: Log Loss score=0.691910, mean score=0.663957, stdev=0.051637 epochs=211, time=0:00:21.84\n",
      "Bootstrap #39: Log Loss score=0.564533, mean score=0.661408, stdev=0.053338 epochs=300, time=0:00:27.64\n",
      "Bootstrap #40: Log Loss score=0.672878, mean score=0.661694, stdev=0.052697 epochs=228, time=0:00:22.68\n",
      "Bootstrap #41: Log Loss score=0.697500, mean score=0.662568, stdev=0.052343 epochs=173, time=0:00:20.94\n",
      "Bootstrap #42: Log Loss score=0.622054, mean score=0.661603, stdev=0.052084 epochs=466, time=0:00:38.57\n",
      "Bootstrap #43: Log Loss score=0.633089, mean score=0.660940, stdev=0.051654 epochs=209, time=0:00:19.26\n",
      "Bootstrap #44: Log Loss score=0.677517, mean score=0.661317, stdev=0.051123 epochs=154, time=0:00:14.55\n",
      "Bootstrap #45: Log Loss score=0.648243, mean score=0.661026, stdev=0.050588 epochs=349, time=0:00:29.35\n",
      "Bootstrap #46: Log Loss score=0.649372, mean score=0.660773, stdev=0.050064 epochs=189, time=0:00:17.12\n",
      "Bootstrap #47: Log Loss score=0.686179, mean score=0.661313, stdev=0.049664 epochs=169, time=0:00:15.40\n",
      "Bootstrap #48: Log Loss score=0.748536, mean score=0.663130, stdev=0.050699 epochs=198, time=0:00:18.12\n",
      "Bootstrap #49: Log Loss score=0.729589, mean score=0.664487, stdev=0.051051 epochs=203, time=0:00:20.40\n",
      "Bootstrap #50: Log Loss score=0.647650, mean score=0.664150, stdev=0.050593 epochs=387, time=0:00:33.35\n",
      "Bootstrap #51: Log Loss score=0.680342, mean score=0.664468, stdev=0.050145 epochs=195, time=0:00:19.71\n",
      "Bootstrap #52: Log Loss score=0.759875, mean score=0.666302, stdev=0.051360 epochs=247, time=0:00:47.93\n",
      "Bootstrap #53: Log Loss score=0.676946, mean score=0.666503, stdev=0.050893 epochs=205, time=0:00:46.69\n",
      "Bootstrap #54: Log Loss score=0.733362, mean score=0.667741, stdev=0.051219 epochs=183, time=0:00:42.26\n",
      "Bootstrap #55: Log Loss score=0.576760, mean score=0.666087, stdev=0.052187 epochs=427, time=0:01:30.13\n",
      "Bootstrap #56: Log Loss score=0.611262, mean score=0.665108, stdev=0.052226 epochs=332, time=0:00:47.72\n",
      "Bootstrap #57: Log Loss score=0.633790, mean score=0.664559, stdev=0.051929 epochs=194, time=0:00:20.82\n",
      "Bootstrap #58: Log Loss score=0.610541, mean score=0.663627, stdev=0.051957 epochs=468, time=0:00:48.95\n",
      "Bootstrap #59: Log Loss score=0.677430, mean score=0.663861, stdev=0.051546 epochs=174, time=0:00:20.36\n",
      "Bootstrap #60: Log Loss score=0.710582, mean score=0.664640, stdev=0.051463 epochs=198, time=0:00:28.31\n",
      "Bootstrap #61: Log Loss score=0.692407, mean score=0.665095, stdev=0.051161 epochs=241, time=0:00:53.74\n",
      "Bootstrap #62: Log Loss score=0.552722, mean score=0.663283, stdev=0.052685 epochs=413, time=0:01:27.21\n",
      "Bootstrap #63: Log Loss score=0.657513, mean score=0.663191, stdev=0.052270 epochs=281, time=0:01:08.38\n",
      "Bootstrap #64: Log Loss score=0.644851, mean score=0.662904, stdev=0.051910 epochs=190, time=0:00:37.83\n",
      "Bootstrap #65: Log Loss score=0.664352, mean score=0.662927, stdev=0.051509 epochs=216, time=0:00:19.36\n",
      "Bootstrap #66: Log Loss score=0.614545, mean score=0.662194, stdev=0.051458 epochs=350, time=0:00:29.35\n",
      "Bootstrap #67: Log Loss score=0.667012, mean score=0.662266, stdev=0.051076 epochs=264, time=0:00:23.00\n",
      "Bootstrap #68: Log Loss score=0.739529, mean score=0.663402, stdev=0.051545 epochs=151, time=0:00:14.74\n",
      "Bootstrap #69: Log Loss score=0.703156, mean score=0.663978, stdev=0.051390 epochs=264, time=0:00:23.85\n",
      "Bootstrap #70: Log Loss score=0.674038, mean score=0.664122, stdev=0.051036 epochs=197, time=0:00:18.21\n",
      "Bootstrap #71: Log Loss score=0.646751, mean score=0.663877, stdev=0.050716 epochs=268, time=0:00:23.23\n",
      "Bootstrap #72: Log Loss score=0.700058, mean score=0.664380, stdev=0.050540 epochs=215, time=0:00:21.22\n",
      "Bootstrap #73: Log Loss score=0.626729, mean score=0.663864, stdev=0.050384 epochs=240, time=0:00:28.83\n",
      "Bootstrap #74: Log Loss score=0.760293, mean score=0.665167, stdev=0.051266 epochs=169, time=0:00:20.10\n",
      "Bootstrap #75: Log Loss score=0.592965, mean score=0.664204, stdev=0.051592 epochs=401, time=0:00:40.01\n",
      "Bootstrap #76: Log Loss score=0.677105, mean score=0.664374, stdev=0.051272 epochs=237, time=0:00:28.99\n",
      "Bootstrap #77: Log Loss score=0.718122, mean score=0.665072, stdev=0.051300 epochs=191, time=0:00:24.21\n",
      "Bootstrap #78: Log Loss score=0.675286, mean score=0.665203, stdev=0.050983 epochs=184, time=0:00:23.71\n",
      "Bootstrap #79: Log Loss score=0.717319, mean score=0.665863, stdev=0.050994 epochs=233, time=0:00:26.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap #80: Log Loss score=0.649941, mean score=0.665664, stdev=0.050705 epochs=207, time=0:00:24.09\n",
      "Bootstrap #81: Log Loss score=0.710189, mean score=0.666213, stdev=0.050630 epochs=199, time=0:00:26.83\n",
      "Bootstrap #82: Log Loss score=0.574302, mean score=0.665092, stdev=0.051322 epochs=341, time=0:00:35.00\n",
      "Bootstrap #83: Log Loss score=0.686869, mean score=0.665355, stdev=0.051067 epochs=223, time=0:00:28.01\n",
      "Bootstrap #84: Log Loss score=0.637058, mean score=0.665018, stdev=0.050855 epochs=239, time=0:00:29.53\n",
      "Bootstrap #85: Log Loss score=0.601013, mean score=0.664265, stdev=0.051024 epochs=518, time=0:00:52.86\n",
      "Bootstrap #86: Log Loss score=0.695617, mean score=0.664629, stdev=0.050837 epochs=197, time=0:00:23.18\n",
      "Bootstrap #87: Log Loss score=0.632398, mean score=0.664259, stdev=0.050661 epochs=255, time=0:00:29.14\n",
      "Bootstrap #88: Log Loss score=0.626079, mean score=0.663825, stdev=0.050534 epochs=190, time=0:00:21.34\n",
      "Bootstrap #89: Log Loss score=0.681632, mean score=0.664025, stdev=0.050285 epochs=170, time=0:00:20.68\n",
      "Bootstrap #90: Log Loss score=0.687816, mean score=0.664290, stdev=0.050067 epochs=246, time=0:00:24.92\n",
      "Bootstrap #91: Log Loss score=0.643370, mean score=0.664060, stdev=0.049839 epochs=355, time=0:00:41.95\n",
      "Bootstrap #92: Log Loss score=0.684528, mean score=0.664282, stdev=0.049613 epochs=207, time=0:00:22.57\n",
      "Bootstrap #93: Log Loss score=0.691571, mean score=0.664576, stdev=0.049425 epochs=292, time=0:00:32.00\n",
      "Bootstrap #94: Log Loss score=0.687497, mean score=0.664819, stdev=0.049218 epochs=246, time=0:00:28.28\n",
      "Bootstrap #95: Log Loss score=0.725585, mean score=0.665459, stdev=0.049349 epochs=205, time=0:00:29.41\n",
      "Bootstrap #96: Log Loss score=0.563482, mean score=0.664397, stdev=0.050172 epochs=264, time=0:00:28.07\n",
      "Bootstrap #97: Log Loss score=0.741612, mean score=0.665193, stdev=0.050518 epochs=208, time=0:00:22.08\n",
      "Bootstrap #98: Log Loss score=0.701914, mean score=0.665568, stdev=0.050395 epochs=192, time=0:00:22.57\n",
      "Bootstrap #99: Log Loss score=0.660745, mean score=0.665519, stdev=0.050142 epochs=197, time=0:00:25.65\n",
      "Bootstrap #100: Log Loss score=0.603433, mean score=0.664898, stdev=0.050272 epochs=238, time=0:00:25.15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import statistics\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
    "\n",
    "SPLITS = 100\n",
    "\n",
    "# Bootstrap\n",
    "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
    "\n",
    "# Track progress\n",
    "mean_benchmark = []\n",
    "num = 0\n",
    "\n",
    "# Loop through samples\n",
    "for train, test in boot.split(x,df['product']):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Split train and test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construct neural network\n",
    "    # kernel_initializer = tensorflow.keras.initializers.he_uniform(seed=None)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation=PReLU()\n",
    "            #kernel_regularizer=regularizers.l2(1e-4)\n",
    "    )) # Hidden 1\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation=PReLU()\n",
    "            #activity_regularizer=regularizers.l2(1e-4)\n",
    "    )) # Hidden 2\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation=PReLU()\n",
    "            #activity_regularizer=regularizers.l2(1e-4)\n",
    "    )) # Hidden 2\n",
    "#    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train on the bootstrap sample\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    \n",
    "    # Predict on the out of boot (validation)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # Measure this bootstrap's log loss\n",
    "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
    "    score = metrics.log_loss(y_compare, pred)\n",
    "    mean_benchmark.append(score)\n",
    "    m = statistics.mean(mean_benchmark)\n",
    "    mdev = statistics.pstdev(mean_benchmark)\n",
    "    \n",
    "    # Record this iteration\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"Bootstrap #{num}: Log Loss score={score:.6f}, mean score={m:.6f}, stdev={mdev:.6f} epochs={epochs}, time={hms_string(time_took)}\")\n",
    "# https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404\n",
    "\n",
    "# 100 Prelu 0.5 1-2, He init\n",
    "# Bootstrap #100: Log Loss score=0.604399, mean score=0.651921, stdev=0.045944 epochs=298, time=0:00:40.12\n",
    "# 100 Prelu 0.5 1-2\n",
    "# Bootstrap #53: Log Loss score=0.652944, mean score=0.655620, stdev=0.050328 epochs=269, time=0:00:51.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-2.0)",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
