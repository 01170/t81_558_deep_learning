{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 13: Advanced/Other Topics**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13 Video Material\n",
    "\n",
    "* **Part 13.1: Flask and Deep Learning Web Services** [[Video]]() [[Notebook]](t81_558_class_13_01_flask.ipynb)\n",
    "* Part 13.2: Deploying a Model to AWS  [[Video]]() [[Notebook]](t81_558_class_13_01_flask.ipynb)\n",
    "* Part 13.3: Using a Keras Deep Neural Network with a Web Application  [[Video]]() [[Notebook]](t81_558_class_13_01_flask.ipynb)\n",
    "* Part 13.4: When to Retrain Your Neural Network [[Video]]() [[Notebook]](t81_558_class_13_01_flask.ipynb)\n",
    "* Part 13.5: AI at the Edge: Using Keras on a Mobile Device  [[Video]]() [[Notebook]](t81_558_class_13_01_flask.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 13.1: Flask and Deep Learning Web Services\n",
    "\n",
    "If your neural networks are to be woven into a production system they must be exposed in a way that they can be easily executed by Python and other programming languages.  The usual means for doing this is a web service. One of the most popular libraries for doing this in Python is [Flask](https://palletsprojects.com/p/flask/). This library allows you to quickly deploy your Python applications, including TensorFlow, as web services.\n",
    "\n",
    "Deployment is a complex process, usually carried out by a company's [Information Technology (IT) group](https://en.wikipedia.org/wiki/Information_technology).  When large numbers of clients must access your model scalability becomes important.  This is usually handled by the cloud.  Flask is not designed for high-volume systems.  When deployed to production, models will usually be wrapped in [Gunicorn](https://gunicorn.org/) or TensorFlow Serving.  High volume cloud deployment is discussed in the next chapter.  Everything presented in this part ith Flask is directly compatible with the higher volume Gunicorn system. It is common to use a development system, such as Flask, when you are developing your initial system.\n",
    "\n",
    "### Other Material\n",
    "\n",
    "The following articles might also be useful for greater understanding of Flask.\n",
    "\n",
    "* [Flask Quickstart](https://flask.palletsprojects.com/en/1.0.x/quickstart/)\n",
    "\n",
    "### Flask Hello World\n",
    "\n",
    "It is uncommon to run Flask from a Jupyter notebook.  Flask is the server and Jupyter usually fills the role of the client.  However, we can run a simple web service from Jupyter.  We will quickly move beyond this and deploy using a Python script (.py).  This means that it will be difficult to use Google CoLab, as you will be running from the command line.  For now, lets execute a Flask web container in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program simply starts a web service on port 9000 of your computer.  This cell will remain running (appearing locked up).  However, it is simply waiting for browsers to connect.  If you point your browser at the following URL, you will interact with the Flask web service.\n",
    "\n",
    "* http://localhost:9000/\n",
    "\n",
    "You should see Hello World displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPG Flask\n",
    "\n",
    "Usually you will interact with a web service through JSON.  A JSON message will be sent to your Flask application and a JSON response will be returned.  Later, in module 13.3, we will see how to attach this web service to a web application that you can interact with through a browser.  We will create a Flask wrapper for a neural network that predicts the miles per gallon for a car.  The sample JSON will look like this.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"cylinders\": 8, \n",
    "  \"displacement\": 300,\n",
    "  \"horsepower\": 78, \n",
    "  \"weight\": 3500,\n",
    "  \"acceleration\": 20, \n",
    "  \"year\": 76,\n",
    "  \"origin\": 1\n",
    "}\n",
    "```\n",
    "\n",
    "We will see two different means of POSTing this JSON data to our web server.  First, we will use a utility called [POSTman](https://www.getpostman.com/).  Secondly, we will use Python code to construct the JSON message and interact with Flask. \n",
    "\n",
    "First, it is necessary to train a neural network with the MPG dataset.  This is very similar to what we've done many times before.  However, we will save the neural network so that we can load it later.  We do not want to have Flask actually train the neural network.  We wish to have the neural network already trained and simply deploy the already trained .H5 file that we save the neural network to.  The following code trains a MPG neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "cars = df['name']\n",
    "\n",
    "# Handle missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Split into validation and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we evaluate the score.  This is more of a sanity check to ensure the code above worked as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"After load score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we save the neural network to a .H5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"./dnn/\",\"mpg_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like the Flask web service to check that the input JSON is valid.  To do this, we need to know what values we expect and what their logical ranges are.  The following code outputs the expected fields, their ranges, and packages all of this information into a JSON object that is copied to the Flask web application.  This will allow us to validate the incoming JSON requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in df.columns if x not in ('mpg','name')]\n",
    "\n",
    "print(\"{\")\n",
    "for i,name in enumerate(cols):\n",
    "    print(f'\"{name}\":{{\"min\":{df[name].min()},\"max\":{df[name].max()}}}{\",\" if i<(len(cols)-1) else \"\"}')\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we setup Python code that will call the model for a single car and get a prediction.  This code will also be copied to the Flask web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model = load_model(os.path.join(\"./dnn/\",\"mpg_model.h5\"))\n",
    "x = np.zeros( (1,7) )\n",
    "\n",
    "x[0,0] = 8 # 'cylinders', \n",
    "x[0,1] = 400 # 'displacement', \n",
    "x[0,2] = 80 # 'horsepower', \n",
    "x[0,3] = 2000 # 'weight',\n",
    "x[0,4] = 19 # 'acceleration', \n",
    "x[0,5] = 72 # 'year', \n",
    "x[0,6] = 1 # 'origin'\n",
    "\n",
    "\n",
    "pred = model.predict(x)\n",
    "float(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The completed web application can be found here:\n",
    "    \n",
    "* [mpg_server_1.py](./py/mpg_server_1.py)\n",
    "\n",
    "This server can be run from the command line with:\n",
    "\n",
    "```\n",
    "python mpg_server_1.py\n",
    "```\n",
    "\n",
    "If you are using a virtual environment (described in Module 1.1), make sure to use the ```activate tensorflow``` command for Windows or ```source activate tensorflow``` for Mac before executing the above command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask MPG Client\n",
    "\n",
    "Now that we have a web service running we would like to access it.  This is a bit more complex than the \"Hello World\" web server we first saw in this part.  The request to display was an HTTP GET.  We must now do an HTTP POST.  To accomplish this you must use a client.  We will see both how to use [PostMan](https://www.getpostman.com/), as well as directly through a Python program in Jupyter.\n",
    "\n",
    "We will begin with PostMan.  If you have not already done so, install PostMan.  \n",
    "\n",
    "To successfully use PostMan to query your web service you must enter the following settings:\n",
    "\n",
    "* POST Request to http://localhost:5000/api/mpg\n",
    "* RAW JSON and paste in JSON from above\n",
    "* Click Send and you should get a correct result\n",
    "\n",
    "The following shows a successful result.\n",
    "\n",
    "![PostMan JSON](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/postman-1.png \"PostMan JSON\")\n",
    "\n",
    "This same process can be done programmatically in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "json = {\n",
    "  \"cylinders\": 8, \n",
    "  \"displacement\": 300,\n",
    "  \"horsepower\": 78, \n",
    "  \"weight\": 3500,\n",
    "  \"acceleration\": 20, \n",
    "  \"year\": 76,\n",
    "  \"origin\": 1\n",
    "}\n",
    "\n",
    "r = requests.post(\"http://localhost:5000/api/mpg\",json=json)\n",
    "if r.status_code == 200:\n",
    "    print(\"Success: {}\".format(r.text))\n",
    "else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images and Web Services\n",
    "\n",
    "We can also accept images from web services.  We will create web service that accepts images and classifies them using MobileNet.  To use your own neural network you will follow the same process just load your own network like we did for the MPG example. The completed web service can be found here:\n",
    "\n",
    "[image_server_1.py](./py/image_server_1.py)\n",
    "\n",
    "This server can be run from the command line with:\n",
    "\n",
    "```\n",
    "python mpg_server_1.py\n",
    "```\n",
    "\n",
    "If you are using a virtual environment (described in Module 1.1), make sure to use the ```activate tensorflow``` command for Windows or ```source activate tensorflow``` for Mac before executing the above command.\n",
    "\n",
    "To successfully use PostMan to query your web service you must enter the following settings:\n",
    "\n",
    "* POST Request to http://localhost:5000/api/image\n",
    "* Use \"Form Data\" and create one entry named \"image\" that is a file.  Choose an image file to classify.\n",
    "* Click Send and you should get a correct result\n",
    "\n",
    "The following shows a successful result.\n",
    "\n",
    "![PostMan Image](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/postman-2.png \"PostMan Image\")\n",
    "\n",
    "This same process can be done programmatically in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.post('http://localhost:5000/api/image', files=dict(image=('hickory.jpeg',open('./photos/hickory.jpeg','rb'))))\n",
    "if response.status_code == 200:\n",
    "    print(\"Success: {}\".format(response.text))\n",
    "else: print(\"Failure: {}\".format(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "rga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
