{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 4: Training for Tabular Data**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Video Material\n",
    "\n",
    "Main video lecture:\n",
    "\n",
    "* [Part 4.1: Encoding a Feature Vector for Keras Deep Learning](https://www.youtube.com/watch?v=ATuyK_HWZgc&index=12&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 4.2: Keras Multiclass Classification for Deep Neural Networks with ROC and AUC](https://www.youtube.com/watch?v=hXkZqGi5mB4&index=13&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 4.3: Keras Regression for Deep Neural Networks with RMSE](https://www.youtube.com/watch?v=SIyMm5DFwQ8&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 4.4: Backpropagation, Nesterov Momentum, and ADAM Neural Network Training](https://www.youtube.com/watch?v=iMyGyZYE9Lc)\n",
    "* [Part 4.5: Neural Network RMSE and Log Loss Error Calculation from Scratch](https://www.youtube.com/watch?v=iMyGyZYE9Lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4.1: Encoding a Feature Vector for Keras Deep Learning\n",
    "\n",
    "Neural networks can accept many types of data.  We will begin with tabular data, where there are well defined rows and columns.  This is the sort of data you would typically see in Microsoft Excel.  An example of tabular data is shown below.\n",
    "\n",
    "Neural networks require numeric input.  This numeric form is called a feature vector.  Each row of training data typically becomes one vector.  The individual input neurons each receive one feature (or column) from this vector.  In this section, we will see how to encode the following tabular data into a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>crime</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>kd</td>\n",
       "      <td>c</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.207723</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.361216</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id job area   income     aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0   1  vv    c  50876.0  13.100000              1      9.017895         35   \n",
       "1   2  kd    c  60369.0  18.625000              2      7.766643         59   \n",
       "2   3  pe    c  55126.0  34.766667              1      3.632069          6   \n",
       "3   4  11    c  51690.0  15.808333              1      5.372942         16   \n",
       "4   5  kl    d  28347.0  40.941667              3      3.822477         20   \n",
       "\n",
       "   dist_unhealthy  age  pop_dense  retail_dense     crime product  \n",
       "0       11.738935   49   0.885827      0.492126  0.071100       b  \n",
       "1        6.805396   51   0.874016      0.342520  0.400809       c  \n",
       "2       13.671772   44   0.944882      0.724409  0.207723       b  \n",
       "3        4.333286   50   0.889764      0.444882  0.361216       b  \n",
       "4        5.967121   38   0.744094      0.661417  0.068033       a  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "display(df[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following observations can be made from the above data:\n",
    "* The target column is the column that you seek to predict.  There are several candidates here.  However, we will initially use product.  This field specifies what product someone bought.\n",
    "* There is an ID column.  This column should not be fed into the neural network as it contains no information useful for prediction.\n",
    "* Many of these fields are numeric and might not require any further processing.\n",
    "* The income column does have some missing values.\n",
    "* There are categorical values: job, area, and product.\n",
    "\n",
    "To begin with, we will convert the job code into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_11</th>\n",
       "      <th>job_al</th>\n",
       "      <th>job_am</th>\n",
       "      <th>job_ax</th>\n",
       "      <th>job_bf</th>\n",
       "      <th>job_by</th>\n",
       "      <th>job_cv</th>\n",
       "      <th>job_de</th>\n",
       "      <th>job_dz</th>\n",
       "      <th>job_e2</th>\n",
       "      <th>...</th>\n",
       "      <th>job_pe</th>\n",
       "      <th>job_po</th>\n",
       "      <th>job_pq</th>\n",
       "      <th>job_pz</th>\n",
       "      <th>job_qp</th>\n",
       "      <th>job_qw</th>\n",
       "      <th>job_rn</th>\n",
       "      <th>job_sa</th>\n",
       "      <th>job_vv</th>\n",
       "      <th>job_zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_11  job_al  job_am  job_ax  job_bf  job_by  job_cv  job_de  job_dz  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       1       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       1       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   job_e2  ...  job_pe  job_po  job_pq  job_pz  job_qp  job_qw  job_rn  \\\n",
       "0       0  ...       0       0       0       0       0       0       0   \n",
       "1       0  ...       0       0       0       0       0       0       0   \n",
       "2       0  ...       1       0       0       0       0       0       0   \n",
       "3       0  ...       0       0       0       0       0       0       0   \n",
       "4       0  ...       0       0       0       0       0       0       0   \n",
       "5       1  ...       0       0       0       0       0       0       0   \n",
       "6       0  ...       0       0       0       0       0       0       0   \n",
       "7       0  ...       0       0       0       0       0       0       0   \n",
       "8       0  ...       0       0       0       0       0       0       0   \n",
       "9       0  ...       1       0       0       0       0       0       0   \n",
       "\n",
       "   job_sa  job_vv  job_zz  \n",
       "0       0       1       0  \n",
       "1       0       0       0  \n",
       "2       0       0       0  \n",
       "3       0       0       0  \n",
       "4       0       0       0  \n",
       "5       0       0       0  \n",
       "6       0       0       0  \n",
       "7       0       0       0  \n",
       "8       0       0       0  \n",
       "9       0       0       0  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df['job'],prefix=\"job\")\n",
    "print(dummies.shape)\n",
    "display(dummies[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are 33 different job codes, there are 33 dummy variables.  We also specified a prefix, because the job codes (such as \"ax\") are not that meaningful by themselves.  Something such as \"job_ax\" also tells us the origin of this field.\n",
    "\n",
    "Next, we must merge these dummies back into the main data frame.  We also drop the original \"job\" field, as it is now represented by the dummies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>...</th>\n",
       "      <th>job_pe</th>\n",
       "      <th>job_po</th>\n",
       "      <th>job_pq</th>\n",
       "      <th>job_pz</th>\n",
       "      <th>job_qp</th>\n",
       "      <th>job_qw</th>\n",
       "      <th>job_rn</th>\n",
       "      <th>job_sa</th>\n",
       "      <th>job_vv</th>\n",
       "      <th>job_zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>d</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>70854.0</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.893343</td>\n",
       "      <td>87</td>\n",
       "      <td>20.340593</td>\n",
       "      <td>43</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>d</td>\n",
       "      <td>38726.0</td>\n",
       "      <td>30.975000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>33</td>\n",
       "      <td>9.480399</td>\n",
       "      <td>39</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>55162.0</td>\n",
       "      <td>26.966667</td>\n",
       "      <td>2</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>17</td>\n",
       "      <td>29.219896</td>\n",
       "      <td>44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>c</td>\n",
       "      <td>67311.0</td>\n",
       "      <td>32.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>25.093772</td>\n",
       "      <td>169</td>\n",
       "      <td>10.927357</td>\n",
       "      <td>45</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>63344.0</td>\n",
       "      <td>38.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>2.816034</td>\n",
       "      <td>3</td>\n",
       "      <td>21.915695</td>\n",
       "      <td>42</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id area   income     aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0   1    c  50876.0  13.100000              1      9.017895         35   \n",
       "1   2    c  60369.0  18.625000              2      7.766643         59   \n",
       "2   3    c  55126.0  34.766667              1      3.632069          6   \n",
       "3   4    c  51690.0  15.808333              1      5.372942         16   \n",
       "4   5    d  28347.0  40.941667              3      3.822477         20   \n",
       "5   6    c  70854.0  40.400000              1     14.893343         87   \n",
       "6   7    d  38726.0  30.975000              3      3.822477         33   \n",
       "7   8    a  55162.0  26.966667              2      4.312097         17   \n",
       "8   9    c  67311.0  32.383333              0     25.093772        169   \n",
       "9  10    a  63344.0  38.233333              1      2.816034          3   \n",
       "\n",
       "   dist_unhealthy  age  pop_dense  ...  job_pe  job_po job_pq  job_pz  job_qp  \\\n",
       "0       11.738935   49   0.885827  ...       0       0      0       0       0   \n",
       "1        6.805396   51   0.874016  ...       0       0      0       0       0   \n",
       "2       13.671772   44   0.944882  ...       1       0      0       0       0   \n",
       "3        4.333286   50   0.889764  ...       0       0      0       0       0   \n",
       "4        5.967121   38   0.744094  ...       0       0      0       0       0   \n",
       "5       20.340593   43   0.866142  ...       0       0      0       0       0   \n",
       "6        9.480399   39   0.976378  ...       0       0      0       0       0   \n",
       "7       29.219896   44   1.000000  ...       0       0      0       0       0   \n",
       "8       10.927357   45   0.952756  ...       0       0      0       0       0   \n",
       "9       21.915695   42   0.897638  ...       1       0      0       0       0   \n",
       "\n",
       "   job_qw  job_rn  job_sa  job_vv  job_zz  \n",
       "0       0       0       0       1       0  \n",
       "1       0       0       0       0       0  \n",
       "2       0       0       0       0       0  \n",
       "3       0       0       0       0       0  \n",
       "4       0       0       0       0       0  \n",
       "5       0       0       0       0       0  \n",
       "6       0       0       0       0       0  \n",
       "7       0       0       0       0       0  \n",
       "8       0       0       0       0       0  \n",
       "9       0       0       0       0       0  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([df,dummies],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "display(df[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce dummy variables for the area column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>...</th>\n",
       "      <th>job_qp</th>\n",
       "      <th>job_qw</th>\n",
       "      <th>job_rn</th>\n",
       "      <th>job_sa</th>\n",
       "      <th>job_vv</th>\n",
       "      <th>job_zz</th>\n",
       "      <th>area_a</th>\n",
       "      <th>area_b</th>\n",
       "      <th>area_c</th>\n",
       "      <th>area_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>70854.0</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.893343</td>\n",
       "      <td>87</td>\n",
       "      <td>20.340593</td>\n",
       "      <td>43</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>38726.0</td>\n",
       "      <td>30.975000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>33</td>\n",
       "      <td>9.480399</td>\n",
       "      <td>39</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>55162.0</td>\n",
       "      <td>26.966667</td>\n",
       "      <td>2</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>17</td>\n",
       "      <td>29.219896</td>\n",
       "      <td>44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>67311.0</td>\n",
       "      <td>32.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>25.093772</td>\n",
       "      <td>169</td>\n",
       "      <td>10.927357</td>\n",
       "      <td>45</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.681102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>63344.0</td>\n",
       "      <td>38.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>2.816034</td>\n",
       "      <td>3</td>\n",
       "      <td>21.915695</td>\n",
       "      <td>42</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   income     aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0   1  50876.0  13.100000              1      9.017895         35   \n",
       "1   2  60369.0  18.625000              2      7.766643         59   \n",
       "2   3  55126.0  34.766667              1      3.632069          6   \n",
       "3   4  51690.0  15.808333              1      5.372942         16   \n",
       "4   5  28347.0  40.941667              3      3.822477         20   \n",
       "5   6  70854.0  40.400000              1     14.893343         87   \n",
       "6   7  38726.0  30.975000              3      3.822477         33   \n",
       "7   8  55162.0  26.966667              2      4.312097         17   \n",
       "8   9  67311.0  32.383333              0     25.093772        169   \n",
       "9  10  63344.0  38.233333              1      2.816034          3   \n",
       "\n",
       "   dist_unhealthy  age  pop_dense  retail_dense  ...  job_qp job_qw  job_rn  \\\n",
       "0       11.738935   49   0.885827      0.492126  ...       0      0       0   \n",
       "1        6.805396   51   0.874016      0.342520  ...       0      0       0   \n",
       "2       13.671772   44   0.944882      0.724409  ...       0      0       0   \n",
       "3        4.333286   50   0.889764      0.444882  ...       0      0       0   \n",
       "4        5.967121   38   0.744094      0.661417  ...       0      0       0   \n",
       "5       20.340593   43   0.866142      0.673228  ...       0      0       0   \n",
       "6        9.480399   39   0.976378      0.874016  ...       0      0       0   \n",
       "7       29.219896   44   1.000000      0.724409  ...       0      0       0   \n",
       "8       10.927357   45   0.952756      0.681102  ...       0      0       0   \n",
       "9       21.915695   42   0.897638      0.724409  ...       0      0       0   \n",
       "\n",
       "   job_sa  job_vv  job_zz  area_a  area_b  area_c  area_d  \n",
       "0       0       1       0       0       0       1       0  \n",
       "1       0       0       0       0       0       1       0  \n",
       "2       0       0       0       0       0       1       0  \n",
       "3       0       0       0       0       0       1       0  \n",
       "4       0       0       0       0       0       0       1  \n",
       "5       0       0       0       0       0       1       0  \n",
       "6       0       0       0       0       0       0       1  \n",
       "7       0       0       0       1       0       0       0  \n",
       "8       0       0       0       0       0       1       0  \n",
       "9       0       0       0       1       0       0       0  \n",
       "\n",
       "[10 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "display(df[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last remaining transformation is to fill in missing income values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more advanced ways of filling in missing values, but they require more analysis.  The idea would be to see if another field might give a hint as to what the income were.  For example, it might be beneficial to calculate a median income for each of the areas or job categories.  This is something to keep in mind for the class Kaggle competition.\n",
    "\n",
    "At this point, the Pandas dataframe is ready to be converted to Numpy for neural network training. We need to know a list of the columns that will make up *x* (the predictors or inputs) and *y* (the target). \n",
    "\n",
    "The complete list of columns is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'income', 'aspect', 'subscriptions', 'dist_healthy', 'save_rate', 'dist_unhealthy', 'age', 'pop_dense', 'retail_dense', 'crime', 'product', 'job_11', 'job_al', 'job_am', 'job_ax', 'job_bf', 'job_by', 'job_cv', 'job_de', 'job_dz', 'job_e2', 'job_f8', 'job_gj', 'job_gv', 'job_kd', 'job_ke', 'job_kl', 'job_kp', 'job_ks', 'job_kw', 'job_mm', 'job_nb', 'job_nn', 'job_ob', 'job_pe', 'job_po', 'job_pq', 'job_pz', 'job_qp', 'job_qw', 'job_rn', 'job_sa', 'job_vv', 'job_zz', 'area_a', 'area_b', 'area_c', 'area_d']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes both the target and predictors.  We need a list with the target removed.  We also remove **id** because it is not useful for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['income', 'aspect', 'subscriptions', 'dist_healthy', 'save_rate', 'dist_unhealthy', 'age', 'pop_dense', 'retail_dense', 'crime', 'job_11', 'job_al', 'job_am', 'job_ax', 'job_bf', 'job_by', 'job_cv', 'job_de', 'job_dz', 'job_e2', 'job_f8', 'job_gj', 'job_gv', 'job_kd', 'job_ke', 'job_kl', 'job_kp', 'job_ks', 'job_kw', 'job_mm', 'job_nb', 'job_nn', 'job_ob', 'job_pe', 'job_po', 'job_pq', 'job_pz', 'job_qp', 'job_qw', 'job_rn', 'job_sa', 'job_vv', 'job_zz', 'area_a', 'area_b', 'area_c', 'area_d']\n"
     ]
    }
   ],
   "source": [
    "x_columns = df.columns.drop('product').drop('id')\n",
    "print(list(x_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate X and Y for a Classification Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate *x* and *y*.  Note, this is how we generate y for a classification problem.  Regression would not use dummies and would simply encode the numeric value of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the *x* and *y* matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.08760000e+04 1.31000000e+01 1.00000000e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [6.03690000e+04 1.86250000e+01 2.00000000e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [5.51260000e+04 3.47666667e+01 1.00000000e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.85950000e+04 3.94250000e+01 3.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [6.79490000e+04 5.73333333e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [6.14670000e+04 1.68916667e+01 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]]\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x and y values are now ready for a neural network.  Make sure that you construct the neural network for a classification problem.  Specifically,\n",
    "\n",
    "* Classification neural networks have an output neuron count equal to the number of classes.\n",
    "* Classification neural networks should use **categorical_crossentropy** and a **softmax** activation function on the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate X and Y for a Regression Neural Network\n",
    "\n",
    "For a regression neural network, the *x* values are generated the same.  However, *y* does not use dummies.  Make sure to replace **income** with your actual target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['income'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4.2: Keras Multiclass Classification for Deep Neural Networks with ROC and AUC\n",
    "\n",
    "* **Binary Classification** - Classification between two possibilities (positive and negative).  Common in medical testing, does the person have the disease (positive) or not (negative).\n",
    "* **Classification** - Classification between more than 2.  The iris dataset (3-way classification).\n",
    "* **Regression** - Numeric prediction.  How many MPG does a car get? (covered in next video)\n",
    "\n",
    "In this class session we will look at some visualizations for all three.\n",
    "\n",
    "\n",
    "It is important to evaluate the level of error in the results produced by a neural network.  In this part we will look at how to evaluate error for both classification and regression neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification is used to create a model that classifies between only two classes.  These two classes are often called \"positive\" and \"negative\".  Consider the following program that uses the [wcbreast_wdbc dataset](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/datasets_wcbc.ipynb) to classify if a breast tumor is cancerous (malignant) or not (benign).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  worst_radius  worst_texture  worst_perimeter  worst_area  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst_symmetry  worst_fractal_dimension  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/wcbreast_wdbc.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "display(df[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves\n",
    "\n",
    "ROC curves can be a bit confusing.  However, they are very common.  It is important to know how to read them.  Even their name is confusing.  Do not worry about their name, it comes from electrical engineering (EE).\n",
    "\n",
    "Binary classification is common in medical testing.  Often you want to diagnose if someone has a disease.  This can lead to two types of errors, know as false positives and false negatives:\n",
    "\n",
    "* **False Positive** - Your test (neural network) indicated that the patient had the disease; however, the patient did not have the disease.\n",
    "* **False Negative** - Your test (neural network) indicated that the patient did not have the disease; however, the patient did have the disease.\n",
    "* **True Positive** - Your test (neural network) correctly identified that the patient had the disease.\n",
    "* **True Negative** - Your test (neural network) correctly identified that the patient did not have the disease.\n",
    "\n",
    "Types of errors:\n",
    "\n",
    "![Type of Error](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_4_errors.png \"Type of Error\")\n",
    "\n",
    "Neural networks classify in terms of probability of it being positive. However, at what probability do you give a positive result?  Is the cutoff 50%? 90%?  Where you set this cutoff is called the threshold.  Anything above the cutoff is positive, anything below is negative.  Setting this cutoff allows the model to be more sensitive or specific:\n",
    "\n",
    "More info on Sensitivity vs Specificity: [Khan Academy](https://www.youtube.com/watch?v=Z5TtopYX1Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "mu1 = -2\n",
    "mu2 = 2\n",
    "variance = 1\n",
    "sigma = math.sqrt(variance)\n",
    "x1 = np.linspace(mu1 - 5*sigma, mu1 + 4*sigma, 100)\n",
    "x2 = np.linspace(mu2 - 5*sigma, mu2 + 4*sigma, 100)\n",
    "plt.plot(x1, stats.norm.pdf(x1, mu1, sigma)/1,color=\"green\")\n",
    "plt.plot(x2, stats.norm.pdf(x2, mu2, sigma)/1,color=\"red\")\n",
    "plt.axvline(x=-2,color=\"black\")\n",
    "plt.axvline(x=0,color=\"black\")\n",
    "plt.axvline(x=+2,color=\"black\")\n",
    "plt.text(-2.7,0.55,\"Sensative\")\n",
    "plt.text(-0.7,0.55,\"Balanced\")\n",
    "plt.text(1.7,0.55,\"Specific\")\n",
    "plt.ylim([0,0.53])\n",
    "plt.xlim([-5,5])\n",
    "plt.legend(['Negative','Positive'])\n",
    "plt.yticks([])\n",
    "#plt.set_yticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Prepare data - apply z-score to ALL x columns\n",
    "# Only do this if you have no categoricals (and are sure you want to use z-score across the board)\n",
    "x_columns = df.columns.drop('diagnosis').drop('id')\n",
    "for col in x_columns:\n",
    "    df[col] = zscore(df[col])\n",
    "\n",
    "# Convert to numpy - Regression\n",
    "x = df[x_columns].values\n",
    "y = df['diagnosis'].map({'M':1,\"B\":0}) # Binary classification, M is 1 and B is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Chart Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/1000\n",
      "426/426 - 0s - loss: 2.3762 - accuracy: 0.6291 - val_loss: 1.0709 - val_accuracy: 0.6224\n",
      "Epoch 2/1000\n",
      "426/426 - 0s - loss: 0.8737 - accuracy: 0.6315 - val_loss: 0.6315 - val_accuracy: 0.6294\n",
      "Epoch 3/1000\n",
      "426/426 - 0s - loss: 0.5138 - accuracy: 0.6995 - val_loss: 0.3037 - val_accuracy: 0.8252\n",
      "Epoch 4/1000\n",
      "426/426 - 0s - loss: 0.2919 - accuracy: 0.8779 - val_loss: 0.2450 - val_accuracy: 0.9371\n",
      "Epoch 5/1000\n",
      "426/426 - 0s - loss: 0.1845 - accuracy: 0.9272 - val_loss: 0.1920 - val_accuracy: 0.9510\n",
      "Epoch 6/1000\n",
      "426/426 - 0s - loss: 0.1407 - accuracy: 0.9531 - val_loss: 0.0762 - val_accuracy: 0.9720\n",
      "Epoch 7/1000\n",
      "426/426 - 0s - loss: 0.0822 - accuracy: 0.9671 - val_loss: 0.0586 - val_accuracy: 0.9790\n",
      "Epoch 8/1000\n",
      "426/426 - 0s - loss: 0.0653 - accuracy: 0.9812 - val_loss: 0.0496 - val_accuracy: 0.9860\n",
      "Epoch 9/1000\n",
      "426/426 - 0s - loss: 0.0566 - accuracy: 0.9812 - val_loss: 0.0498 - val_accuracy: 0.9790\n",
      "Epoch 10/1000\n",
      "426/426 - 0s - loss: 0.0491 - accuracy: 0.9883 - val_loss: 0.0483 - val_accuracy: 0.9860\n",
      "Epoch 11/1000\n",
      "426/426 - 0s - loss: 0.0444 - accuracy: 0.9883 - val_loss: 0.0473 - val_accuracy: 0.9860\n",
      "Epoch 12/1000\n",
      "426/426 - 0s - loss: 0.0405 - accuracy: 0.9859 - val_loss: 0.0551 - val_accuracy: 0.9860\n",
      "Epoch 13/1000\n",
      "426/426 - 0s - loss: 0.0381 - accuracy: 0.9906 - val_loss: 0.0490 - val_accuracy: 0.9790\n",
      "Epoch 14/1000\n",
      "426/426 - 0s - loss: 0.0333 - accuracy: 0.9930 - val_loss: 0.0501 - val_accuracy: 0.9860\n",
      "Epoch 15/1000\n",
      "426/426 - 0s - loss: 0.0305 - accuracy: 0.9930 - val_loss: 0.0531 - val_accuracy: 0.9860\n",
      "Epoch 16/1000\n",
      "426/426 - 0s - loss: 0.0287 - accuracy: 0.9930 - val_loss: 0.0518 - val_accuracy: 0.9860\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Classification neural network\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=x.shape[1], activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(50,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(1,activation='linear',kernel_initializer='random_normal'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "plot_roc(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification Error Metrics\n",
    "\n",
    "The following sections will examine several metrics for evaluating classification error. The following classification neural network will be used to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 - 0s - loss: 1.5540 - accuracy: 0.3740 - val_loss: 1.1371 - val_accuracy: 0.4980\n",
      "Epoch 2/1000\n",
      "1500/1500 - 0s - loss: 1.1366 - accuracy: 0.4647 - val_loss: 1.0649 - val_accuracy: 0.5020\n",
      "Epoch 3/1000\n",
      "1500/1500 - 0s - loss: 0.9743 - accuracy: 0.5680 - val_loss: 0.9362 - val_accuracy: 0.5900\n",
      "Epoch 4/1000\n",
      "1500/1500 - 0s - loss: 0.8371 - accuracy: 0.6693 - val_loss: 0.8369 - val_accuracy: 0.6560\n",
      "Epoch 5/1000\n",
      "1500/1500 - 0s - loss: 0.7857 - accuracy: 0.6853 - val_loss: 0.7993 - val_accuracy: 0.6800\n",
      "Epoch 6/1000\n",
      "1500/1500 - 0s - loss: 0.7599 - accuracy: 0.6867 - val_loss: 0.8007 - val_accuracy: 0.6960\n",
      "Epoch 7/1000\n",
      "1500/1500 - 0s - loss: 0.7434 - accuracy: 0.6980 - val_loss: 0.7839 - val_accuracy: 0.6980\n",
      "Epoch 8/1000\n",
      "1500/1500 - 0s - loss: 0.7317 - accuracy: 0.7007 - val_loss: 0.7701 - val_accuracy: 0.6980\n",
      "Epoch 9/1000\n",
      "1500/1500 - 0s - loss: 0.7164 - accuracy: 0.7020 - val_loss: 0.7964 - val_accuracy: 0.6600\n",
      "Epoch 10/1000\n",
      "1500/1500 - 0s - loss: 0.7103 - accuracy: 0.6980 - val_loss: 0.7831 - val_accuracy: 0.6680\n",
      "Epoch 11/1000\n",
      "1500/1500 - 0s - loss: 0.6920 - accuracy: 0.7080 - val_loss: 0.7618 - val_accuracy: 0.7020\n",
      "Epoch 12/1000\n",
      "1500/1500 - 0s - loss: 0.7084 - accuracy: 0.7000 - val_loss: 0.7708 - val_accuracy: 0.6660\n",
      "Epoch 13/1000\n",
      "1500/1500 - 0s - loss: 0.6900 - accuracy: 0.7053 - val_loss: 0.7732 - val_accuracy: 0.6660\n",
      "Epoch 14/1000\n",
      "1500/1500 - 0s - loss: 0.6827 - accuracy: 0.7073 - val_loss: 0.7402 - val_accuracy: 0.7020\n",
      "Epoch 15/1000\n",
      "1500/1500 - 0s - loss: 0.6735 - accuracy: 0.7087 - val_loss: 0.7459 - val_accuracy: 0.7000\n",
      "Epoch 16/1000\n",
      "1500/1500 - 0s - loss: 0.6676 - accuracy: 0.7067 - val_loss: 0.7411 - val_accuracy: 0.6960\n",
      "Epoch 17/1000\n",
      "1500/1500 - 0s - loss: 0.6575 - accuracy: 0.7153 - val_loss: 0.7372 - val_accuracy: 0.7040\n",
      "Epoch 18/1000\n",
      "1500/1500 - 0s - loss: 0.6531 - accuracy: 0.7200 - val_loss: 0.7373 - val_accuracy: 0.7120\n",
      "Epoch 19/1000\n",
      "1500/1500 - 0s - loss: 0.6526 - accuracy: 0.7240 - val_loss: 0.7439 - val_accuracy: 0.6980\n",
      "Epoch 20/1000\n",
      "1500/1500 - 0s - loss: 0.6558 - accuracy: 0.7207 - val_loss: 0.7385 - val_accuracy: 0.6960\n",
      "Epoch 21/1000\n",
      "1500/1500 - 0s - loss: 0.6428 - accuracy: 0.7280 - val_loss: 0.7358 - val_accuracy: 0.6960\n",
      "Epoch 22/1000\n",
      "1500/1500 - 0s - loss: 0.6498 - accuracy: 0.7147 - val_loss: 0.7306 - val_accuracy: 0.6980\n",
      "Epoch 23/1000\n",
      "1500/1500 - 0s - loss: 0.6348 - accuracy: 0.7300 - val_loss: 0.7310 - val_accuracy: 0.6900\n",
      "Epoch 24/1000\n",
      "1500/1500 - 0s - loss: 0.6346 - accuracy: 0.7387 - val_loss: 0.7299 - val_accuracy: 0.7020\n",
      "Epoch 25/1000\n",
      "1500/1500 - 0s - loss: 0.6317 - accuracy: 0.7313 - val_loss: 0.7278 - val_accuracy: 0.7020\n",
      "Epoch 26/1000\n",
      "1500/1500 - 0s - loss: 0.6240 - accuracy: 0.7260 - val_loss: 0.7255 - val_accuracy: 0.7120\n",
      "Epoch 27/1000\n",
      "1500/1500 - 0s - loss: 0.6238 - accuracy: 0.7293 - val_loss: 0.7221 - val_accuracy: 0.7100\n",
      "Epoch 28/1000\n",
      "1500/1500 - 0s - loss: 0.6152 - accuracy: 0.7333 - val_loss: 0.7395 - val_accuracy: 0.6840\n",
      "Epoch 29/1000\n",
      "1500/1500 - 0s - loss: 0.6356 - accuracy: 0.7287 - val_loss: 0.7398 - val_accuracy: 0.7000\n",
      "Epoch 30/1000\n",
      "1500/1500 - 0s - loss: 0.6218 - accuracy: 0.7453 - val_loss: 0.7212 - val_accuracy: 0.7020\n",
      "Epoch 31/1000\n",
      "1500/1500 - 0s - loss: 0.6156 - accuracy: 0.7427 - val_loss: 0.7712 - val_accuracy: 0.6760\n",
      "Epoch 32/1000\n",
      "1500/1500 - 0s - loss: 0.6292 - accuracy: 0.7267 - val_loss: 0.7243 - val_accuracy: 0.6980\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Classification neural network\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=x.shape[1], activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(50,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer='random_normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax',kernel_initializer='random_normal'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Classification Accuracy\n",
    " \n",
    "Accuracy is the number of rows where the neural network correctly predicted the target class.  Accuracy is only used for classification, not regression.\n",
    "\n",
    "$ accuracy = \\frac{c}{N} $\n",
    "\n",
    "Where $c$ is the number correct and $N$ is the size of the evaluated set (training or validation). Higher accuracy numbers are desired.\n",
    "\n",
    "As we just saw, by default, Keras will return the percent probability for each class. We can change these prediction probabilities into the actual iris predicted with **argmax**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the actual iris flower predicted, we can calculate the percent accuracy (how many were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.702\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Classification Log Loss\n",
    "\n",
    "Accuracy is like a final exam with no partial credit.  However, neural networks can predict a probability of each of the target classes.  Neural networks will give high probabilities to predictions that are more likely.  Log loss is an error metric that penalizes confidence in wrong answers. Lower log loss values are desired.\n",
    "\n",
    "The following code shows the output of predict_proba:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array of predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.0589, 0.6696, 0.2712, 0.0003, 0.    , 0.    ],\n",
       "       [0.    , 0.7502, 0.2483, 0.    , 0.0015, 0.    , 0.    ],\n",
       "       [0.    , 0.6469, 0.3484, 0.0001, 0.0044, 0.0001, 0.    ],\n",
       "       [0.    , 0.3136, 0.6781, 0.0057, 0.0025, 0.    , 0.    ],\n",
       "       [0.    , 0.0159, 0.602 , 0.3821, 0.    , 0.    , 0.    ]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As percent probability\n",
      "[ 0.0001  5.8878 66.9595 27.1179  0.0345  0.0002  0.    ]\n",
      "Log loss score: 0.7211582019142807\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Don't display numpy in scientific notation\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Generate predictions\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "display(pred[0:5])\n",
    "\n",
    "print(\"As percent probability\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))\n",
    "\n",
    "pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Log loss](https://www.kaggle.com/wiki/LogarithmicLoss) is calculated as follows:\n",
    "\n",
    "$ \\text{log loss} = -\\frac{1}{N}\\sum_{i=1}^N {( {y}_i\\log(\\hat{y}_i) + (1 - {y}_i)\\log(1 - \\hat{y}_i))} $\n",
    "\n",
    "The log function is useful to penalizing wrong answers.  The following code demonstrates the utility of the log function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jheaton/miniconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange, sin, pi\n",
    "\n",
    "#t = arange(1e-5, 5.0, 0.00001)\n",
    "#t = arange(1.0, 5.0, 0.00001) # computer scientists\n",
    "t = arange(0.0, 1.0, 0.00001)  # data     scientists\n",
    "\n",
    "fig = figure(1,figsize=(12, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t, np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8, 1.5))\n",
    "ax1.set_xlim((-0.1, 2))\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('log(x)')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 3 1 2 2 2 2 2 1 1 1 2 1 1 2 1 2 1 2 1 5 1 0 1 1 2 1 1 1 1 1 2 1 2\n",
      " 1 2 1 1 1 3 2 2 1 1 2 1 1 1 5 1 1 5 1 2 1 1 2 4 1 2 2 1 2 2 2 2 1 1 1 1 1\n",
      " 2 2 1 1 2 1 2 2 1 3 2 2 1 2 2 1 1 1 1 2 5 1 4 1 2 3 1 1 1 1 1 2 2 1 1 1 2\n",
      " 2 1 2 1 1 1 2 2 3 2 2 2 2 2 0 6 2 3 1 1 1 5 1 1 0 1 2 1 1 1 1 1 2 1 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 2 1 2 1 1 1 1 2 2 1 2 1 2 2 2 2 2 2 1 5 1 2 2 2 2 1 1 4\n",
      " 2 2 1 2 0 2 2 2 2 2 1 1 2 2 2 1 1 1 2 1 1 2 1 2 1 1 2 1 0 0 1 2 1 2 1 1 1\n",
      " 2 0 5 2 1 2 1 1 1 1 2 2 1 1 1 1 1 1 4 1 1 1 1 1 0 0 1 2 1 1 0 2 2 2 2 1 2\n",
      " 1 2 1 1 2 2 1 2 5 2 2 2 1 1 1 1 2 2 1 1 2 0 2 1 2 1 1 1 5 1 2 1 2 0 1 1 1\n",
      " 3 5 2 1 2 1 6 5 1 1 2 1 2 2 1 1 5 2 1 1 2 2 2 1 1 1 2 5 1 2 2 1 2 1 2 2 2\n",
      " 3 1 2 2 2 2 1 2 0 1 1 1 1 0 2 5 0 1 3 2 3 1 2 1 2 2 2 1 2 1 1 1 2 2 1 2 3\n",
      " 1 4 0 1 5 1 2 1 1 2 0 1 1 1 1 1 2 2 2 2 1 1 2 2 1 5 6 2 1 1 2 2 1 1 1 2 2\n",
      " 3 1 1 2 2 1 0 1 1 0 1 2 2 1 3 1 2 4 1 1 1 1 1 1 2 2 2 1 4 2 1 1 1 1 1 2 1\n",
      " 2 1 1 0 1 1 1 2 1 1 1 2 3 1 2 1 1 1 1 1 2 2 2 2 1 2 1 1 2 1 1 1 2 2 4 1 2\n",
      " 0 1 1 2 1 0 2 1 5 1 1 1 2 2 1 2 1 2 1]\n",
      "[2 1 1 2 2 2 2 2 1 2 2 1 2 1 1 1 1 2 1 2 1 2 1 0 1 0 1 1 1 1 2 1 1 1 2 1 2\n",
      " 1 2 2 1 2 3 2 2 1 1 2 1 1 1 0 1 2 0 1 2 1 1 2 1 2 2 2 2 2 1 2 2 2 1 1 2 0\n",
      " 2 1 2 1 2 2 2 2 1 2 1 2 1 2 2 1 1 0 2 2 0 1 1 1 2 3 1 1 1 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 1 2 2 3 2 2 2 1 1 0 0 1 3 1 1 1 0 1 1 1 2 2 2 1 1 2 1 1 2 1 2 2\n",
      " 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 2 2 1 3 1 2 2 2 2 2 2 2 0 1 2 2 1 2 2 1 1\n",
      " 2 1 0 2 0 2 2 2 2 1 2 1 1 2 2 1 2 0 2 2 1 2 1 2 2 1 3 1 0 0 2 2 1 1 1 1 1\n",
      " 2 0 0 2 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 0 0 1 2 1 1 0 2 1 2 2 1 2\n",
      " 2 2 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1 1 1 0 2 1 3 1 1 1 1 1 1 1 2 0 1 1 2\n",
      " 2 1 1 1 2 1 0 0 1 1 1 1 1 2 1 2 0 2 1 1 2 2 1 1 1 2 2 0 1 2 1 1 2 1 2 2 1\n",
      " 3 1 2 1 2 2 2 2 0 1 2 1 1 0 3 1 0 1 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2\n",
      " 1 1 0 1 0 2 1 2 1 2 0 1 1 1 2 1 2 2 1 2 2 2 1 2 1 1 0 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 2 1 0 1 1 0 1 2 2 1 3 2 2 1 2 1 1 1 1 1 2 2 2 1 1 2 1 2 1 1 1 2 1\n",
      " 2 1 1 0 2 1 1 2 1 1 1 2 3 1 2 1 1 2 2 1 2 2 2 1 2 2 2 2 2 1 1 1 2 2 1 1 2\n",
      " 0 2 2 2 0 0 1 1 0 1 2 0 2 2 2 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_compare)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 21   1   0   0   0   0   0]\n",
      " [  7 183  59   0   0   0   0]\n",
      " [  0  43 140   4   0   0   0]\n",
      " [  0   0   7   7   0   0   0]\n",
      " [  0   8   0   0   0   0   0]\n",
      " [ 12   5   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0]]\n",
      "Normalized confusion matrix\n",
      "[[0.95 0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.03 0.73 0.24 0.   0.   0.   0.  ]\n",
      " [0.   0.23 0.75 0.02 0.   0.   0.  ]\n",
      " [0.   0.   0.5  0.5  0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.71 0.29 0.   0.   0.   0.   0.  ]\n",
      " [1.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_compare, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, products)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, products, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4.3: Keras Regression for Deep Neural Networks with RMSE\n",
    "\n",
    "Regression results are evaluated differently than classification.  Consider the following code that trains a neural network for regression on the data set **jh-simple-dataset.csv**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values\n",
    "\n",
    "# Create train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 - 0s - loss: 1913.7001 - val_loss: 1665.3748\n",
      "Epoch 2/1000\n",
      "1500/1500 - 0s - loss: 1414.5846 - val_loss: 1082.9279\n",
      "Epoch 3/1000\n",
      "1500/1500 - 0s - loss: 778.7110 - val_loss: 463.6035\n",
      "Epoch 4/1000\n",
      "1500/1500 - 0s - loss: 323.6336 - val_loss: 238.4932\n",
      "Epoch 5/1000\n",
      "1500/1500 - 0s - loss: 231.4892 - val_loss: 212.1627\n",
      "Epoch 6/1000\n",
      "1500/1500 - 0s - loss: 205.4311 - val_loss: 189.1420\n",
      "Epoch 7/1000\n",
      "1500/1500 - 0s - loss: 181.9524 - val_loss: 168.7042\n",
      "Epoch 8/1000\n",
      "1500/1500 - 0s - loss: 160.4932 - val_loss: 148.2304\n",
      "Epoch 9/1000\n",
      "1500/1500 - 0s - loss: 140.7105 - val_loss: 130.3645\n",
      "Epoch 10/1000\n",
      "1500/1500 - 0s - loss: 122.8737 - val_loss: 114.6369\n",
      "Epoch 11/1000\n",
      "1500/1500 - 0s - loss: 107.1820 - val_loss: 100.7475\n",
      "Epoch 12/1000\n",
      "1500/1500 - 0s - loss: 93.8801 - val_loss: 89.3334\n",
      "Epoch 13/1000\n",
      "1500/1500 - 0s - loss: 82.5547 - val_loss: 79.7650\n",
      "Epoch 14/1000\n",
      "1500/1500 - 0s - loss: 73.2446 - val_loss: 71.9153\n",
      "Epoch 15/1000\n",
      "1500/1500 - 0s - loss: 65.0238 - val_loss: 64.2411\n",
      "Epoch 16/1000\n",
      "1500/1500 - 0s - loss: 58.1889 - val_loss: 58.4755\n",
      "Epoch 17/1000\n",
      "1500/1500 - 0s - loss: 52.4705 - val_loss: 52.9820\n",
      "Epoch 18/1000\n",
      "1500/1500 - 0s - loss: 47.1857 - val_loss: 48.6978\n",
      "Epoch 19/1000\n",
      "1500/1500 - 0s - loss: 42.9858 - val_loss: 44.2975\n",
      "Epoch 20/1000\n",
      "1500/1500 - 0s - loss: 38.8860 - val_loss: 40.7674\n",
      "Epoch 21/1000\n",
      "1500/1500 - 0s - loss: 35.1204 - val_loss: 37.4380\n",
      "Epoch 22/1000\n",
      "1500/1500 - 0s - loss: 32.3365 - val_loss: 34.4564\n",
      "Epoch 23/1000\n",
      "1500/1500 - 0s - loss: 29.4629 - val_loss: 31.9639\n",
      "Epoch 24/1000\n",
      "1500/1500 - 0s - loss: 26.9243 - val_loss: 30.0706\n",
      "Epoch 25/1000\n",
      "1500/1500 - 0s - loss: 25.0796 - val_loss: 27.4639\n",
      "Epoch 26/1000\n",
      "1500/1500 - 0s - loss: 23.0996 - val_loss: 25.7854\n",
      "Epoch 27/1000\n",
      "1500/1500 - 0s - loss: 21.5453 - val_loss: 24.2009\n",
      "Epoch 28/1000\n",
      "1500/1500 - 0s - loss: 20.1175 - val_loss: 22.6929\n",
      "Epoch 29/1000\n",
      "1500/1500 - 0s - loss: 18.9536 - val_loss: 21.1900\n",
      "Epoch 30/1000\n",
      "1500/1500 - 0s - loss: 17.9562 - val_loss: 20.0395\n",
      "Epoch 31/1000\n",
      "1500/1500 - 0s - loss: 16.8927 - val_loss: 19.1331\n",
      "Epoch 32/1000\n",
      "1500/1500 - 0s - loss: 16.1119 - val_loss: 18.1105\n",
      "Epoch 33/1000\n",
      "1500/1500 - 0s - loss: 15.3291 - val_loss: 17.2502\n",
      "Epoch 34/1000\n",
      "1500/1500 - 0s - loss: 14.6656 - val_loss: 16.3874\n",
      "Epoch 35/1000\n",
      "1500/1500 - 0s - loss: 14.0365 - val_loss: 15.6354\n",
      "Epoch 36/1000\n",
      "1500/1500 - 0s - loss: 13.4751 - val_loss: 14.9724\n",
      "Epoch 37/1000\n",
      "1500/1500 - 0s - loss: 12.8627 - val_loss: 14.4179\n",
      "Epoch 38/1000\n",
      "1500/1500 - 0s - loss: 12.4392 - val_loss: 13.7969\n",
      "Epoch 39/1000\n",
      "1500/1500 - 0s - loss: 11.8582 - val_loss: 13.1768\n",
      "Epoch 40/1000\n",
      "1500/1500 - 0s - loss: 11.3964 - val_loss: 12.8381\n",
      "Epoch 41/1000\n",
      "1500/1500 - 0s - loss: 11.0254 - val_loss: 12.3007\n",
      "Epoch 42/1000\n",
      "1500/1500 - 0s - loss: 10.6489 - val_loss: 11.8574\n",
      "Epoch 43/1000\n",
      "1500/1500 - 0s - loss: 10.2430 - val_loss: 11.4610\n",
      "Epoch 44/1000\n",
      "1500/1500 - 0s - loss: 9.9401 - val_loss: 11.2564\n",
      "Epoch 45/1000\n",
      "1500/1500 - 0s - loss: 9.6664 - val_loss: 10.7256\n",
      "Epoch 46/1000\n",
      "1500/1500 - 0s - loss: 9.2102 - val_loss: 10.4357\n",
      "Epoch 47/1000\n",
      "1500/1500 - 0s - loss: 8.8766 - val_loss: 9.9657\n",
      "Epoch 48/1000\n",
      "1500/1500 - 0s - loss: 8.5912 - val_loss: 9.8893\n",
      "Epoch 49/1000\n",
      "1500/1500 - 0s - loss: 8.2240 - val_loss: 9.5697\n",
      "Epoch 50/1000\n",
      "1500/1500 - 0s - loss: 8.0309 - val_loss: 8.8866\n",
      "Epoch 51/1000\n",
      "1500/1500 - 0s - loss: 7.6903 - val_loss: 8.6640\n",
      "Epoch 52/1000\n",
      "1500/1500 - 0s - loss: 7.3889 - val_loss: 8.1652\n",
      "Epoch 53/1000\n",
      "1500/1500 - 0s - loss: 7.0790 - val_loss: 7.7167\n",
      "Epoch 54/1000\n",
      "1500/1500 - 0s - loss: 6.7710 - val_loss: 7.3072\n",
      "Epoch 55/1000\n",
      "1500/1500 - 0s - loss: 6.4498 - val_loss: 6.8566\n",
      "Epoch 56/1000\n",
      "1500/1500 - 0s - loss: 6.2308 - val_loss: 6.5235\n",
      "Epoch 57/1000\n",
      "1500/1500 - 0s - loss: 5.7914 - val_loss: 6.2743\n",
      "Epoch 58/1000\n",
      "1500/1500 - 0s - loss: 5.5490 - val_loss: 5.8581\n",
      "Epoch 59/1000\n",
      "1500/1500 - 0s - loss: 5.3184 - val_loss: 5.5914\n",
      "Epoch 60/1000\n",
      "1500/1500 - 0s - loss: 5.0580 - val_loss: 5.3895\n",
      "Epoch 61/1000\n",
      "1500/1500 - 0s - loss: 4.8509 - val_loss: 5.0655\n",
      "Epoch 62/1000\n",
      "1500/1500 - 0s - loss: 4.6568 - val_loss: 5.0806\n",
      "Epoch 63/1000\n",
      "1500/1500 - 0s - loss: 4.4607 - val_loss: 4.6358\n",
      "Epoch 64/1000\n",
      "1500/1500 - 0s - loss: 4.2394 - val_loss: 4.4788\n",
      "Epoch 65/1000\n",
      "1500/1500 - 0s - loss: 4.0360 - val_loss: 4.2532\n",
      "Epoch 66/1000\n",
      "1500/1500 - 0s - loss: 3.8376 - val_loss: 4.0652\n",
      "Epoch 67/1000\n",
      "1500/1500 - 0s - loss: 3.6724 - val_loss: 3.8739\n",
      "Epoch 68/1000\n",
      "1500/1500 - 0s - loss: 3.5259 - val_loss: 3.6928\n",
      "Epoch 69/1000\n",
      "1500/1500 - 0s - loss: 3.4096 - val_loss: 3.6699\n",
      "Epoch 70/1000\n",
      "1500/1500 - 0s - loss: 3.1969 - val_loss: 3.3988\n",
      "Epoch 71/1000\n",
      "1500/1500 - 0s - loss: 3.0261 - val_loss: 3.2180\n",
      "Epoch 72/1000\n",
      "1500/1500 - 0s - loss: 2.9572 - val_loss: 3.1166\n",
      "Epoch 73/1000\n",
      "1500/1500 - 0s - loss: 2.7574 - val_loss: 2.9658\n",
      "Epoch 74/1000\n",
      "1500/1500 - 0s - loss: 2.6703 - val_loss: 2.8129\n",
      "Epoch 75/1000\n",
      "1500/1500 - 0s - loss: 2.5143 - val_loss: 2.7312\n",
      "Epoch 76/1000\n",
      "1500/1500 - 0s - loss: 2.4120 - val_loss: 2.5638\n",
      "Epoch 77/1000\n",
      "1500/1500 - 0s - loss: 2.3023 - val_loss: 2.4589\n",
      "Epoch 78/1000\n",
      "1500/1500 - 0s - loss: 2.1825 - val_loss: 2.5143\n",
      "Epoch 79/1000\n",
      "1500/1500 - 0s - loss: 2.0938 - val_loss: 2.2701\n",
      "Epoch 80/1000\n",
      "1500/1500 - 0s - loss: 2.0253 - val_loss: 2.1550\n",
      "Epoch 81/1000\n",
      "1500/1500 - 0s - loss: 1.9259 - val_loss: 2.0650\n",
      "Epoch 82/1000\n",
      "1500/1500 - 0s - loss: 1.8492 - val_loss: 2.0337\n",
      "Epoch 83/1000\n",
      "1500/1500 - 0s - loss: 1.7533 - val_loss: 1.8986\n",
      "Epoch 84/1000\n",
      "1500/1500 - 0s - loss: 1.6669 - val_loss: 1.8042\n",
      "Epoch 85/1000\n",
      "1500/1500 - 0s - loss: 1.5943 - val_loss: 1.7284\n",
      "Epoch 86/1000\n",
      "1500/1500 - 0s - loss: 1.5368 - val_loss: 1.6568\n",
      "Epoch 87/1000\n",
      "1500/1500 - 0s - loss: 1.4707 - val_loss: 1.5835\n",
      "Epoch 88/1000\n",
      "1500/1500 - 0s - loss: 1.4225 - val_loss: 1.5413\n",
      "Epoch 89/1000\n",
      "1500/1500 - 0s - loss: 1.3395 - val_loss: 1.5304\n",
      "Epoch 90/1000\n",
      "1500/1500 - 0s - loss: 1.3190 - val_loss: 1.4004\n",
      "Epoch 91/1000\n",
      "1500/1500 - 0s - loss: 1.2491 - val_loss: 1.3755\n",
      "Epoch 92/1000\n",
      "1500/1500 - 0s - loss: 1.2074 - val_loss: 1.4336\n",
      "Epoch 93/1000\n",
      "1500/1500 - 0s - loss: 1.2191 - val_loss: 1.2664\n",
      "Epoch 94/1000\n",
      "1500/1500 - 0s - loss: 1.1170 - val_loss: 1.3822\n",
      "Epoch 95/1000\n",
      "1500/1500 - 0s - loss: 1.0904 - val_loss: 1.1708\n",
      "Epoch 96/1000\n",
      "1500/1500 - 0s - loss: 1.0180 - val_loss: 1.1149\n",
      "Epoch 97/1000\n",
      "1500/1500 - 0s - loss: 0.9932 - val_loss: 1.1339\n",
      "Epoch 98/1000\n",
      "1500/1500 - 0s - loss: 0.9680 - val_loss: 1.0457\n",
      "Epoch 99/1000\n",
      "1500/1500 - 0s - loss: 0.9188 - val_loss: 1.0103\n",
      "Epoch 100/1000\n",
      "1500/1500 - 0s - loss: 0.9116 - val_loss: 0.9847\n",
      "Epoch 101/1000\n",
      "1500/1500 - 0s - loss: 0.8541 - val_loss: 0.9609\n",
      "Epoch 102/1000\n",
      "1500/1500 - 0s - loss: 0.8355 - val_loss: 0.9292\n",
      "Epoch 103/1000\n",
      "1500/1500 - 0s - loss: 0.8370 - val_loss: 1.0135\n",
      "Epoch 104/1000\n",
      "1500/1500 - 0s - loss: 0.7757 - val_loss: 0.9101\n",
      "Epoch 105/1000\n",
      "1500/1500 - 0s - loss: 0.7729 - val_loss: 0.8716\n",
      "Epoch 106/1000\n",
      "1500/1500 - 0s - loss: 0.7382 - val_loss: 0.9280\n",
      "Epoch 107/1000\n",
      "1500/1500 - 0s - loss: 0.7276 - val_loss: 0.8297\n",
      "Epoch 108/1000\n",
      "1500/1500 - 0s - loss: 0.6880 - val_loss: 0.7966\n",
      "Epoch 109/1000\n",
      "1500/1500 - 0s - loss: 0.6597 - val_loss: 0.7934\n",
      "Epoch 110/1000\n",
      "1500/1500 - 0s - loss: 0.6710 - val_loss: 0.7817\n",
      "Epoch 111/1000\n",
      "1500/1500 - 0s - loss: 0.6489 - val_loss: 0.7649\n",
      "Epoch 112/1000\n",
      "1500/1500 - 0s - loss: 0.6336 - val_loss: 0.7774\n",
      "Epoch 113/1000\n",
      "1500/1500 - 0s - loss: 0.6137 - val_loss: 0.7408\n",
      "Epoch 114/1000\n",
      "1500/1500 - 0s - loss: 0.6217 - val_loss: 0.7380\n",
      "Epoch 115/1000\n",
      "1500/1500 - 0s - loss: 0.6377 - val_loss: 0.8185\n",
      "Epoch 116/1000\n",
      "1500/1500 - 0s - loss: 0.6002 - val_loss: 0.8099\n",
      "Epoch 117/1000\n",
      "1500/1500 - 0s - loss: 0.5802 - val_loss: 0.7299\n",
      "Epoch 118/1000\n",
      "1500/1500 - 0s - loss: 0.5807 - val_loss: 0.6770\n",
      "Epoch 119/1000\n",
      "1500/1500 - 0s - loss: 0.5601 - val_loss: 0.6992\n",
      "Epoch 120/1000\n",
      "1500/1500 - 0s - loss: 0.5430 - val_loss: 0.6666\n",
      "Epoch 121/1000\n",
      "1500/1500 - 0s - loss: 0.5597 - val_loss: 0.7957\n",
      "Epoch 122/1000\n",
      "1500/1500 - 0s - loss: 0.5706 - val_loss: 0.6753\n",
      "Epoch 123/1000\n",
      "1500/1500 - 0s - loss: 0.5295 - val_loss: 0.6983\n",
      "Epoch 124/1000\n",
      "1500/1500 - 0s - loss: 0.5329 - val_loss: 0.6393\n",
      "Epoch 125/1000\n",
      "1500/1500 - 0s - loss: 0.5564 - val_loss: 0.6890\n",
      "Epoch 126/1000\n",
      "1500/1500 - 0s - loss: 0.5201 - val_loss: 0.7004\n",
      "Epoch 127/1000\n",
      "1500/1500 - 0s - loss: 0.5034 - val_loss: 0.6632\n",
      "Epoch 128/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 - 0s - loss: 0.5023 - val_loss: 0.6159\n",
      "Epoch 129/1000\n",
      "1500/1500 - 0s - loss: 0.5058 - val_loss: 0.6840\n",
      "Epoch 130/1000\n",
      "1500/1500 - 0s - loss: 0.5188 - val_loss: 0.6057\n",
      "Epoch 131/1000\n",
      "1500/1500 - 0s - loss: 0.5276 - val_loss: 0.5944\n",
      "Epoch 132/1000\n",
      "1500/1500 - 0s - loss: 0.4787 - val_loss: 0.5971\n",
      "Epoch 133/1000\n",
      "1500/1500 - 0s - loss: 0.4853 - val_loss: 0.6151\n",
      "Epoch 134/1000\n",
      "1500/1500 - 0s - loss: 0.4658 - val_loss: 0.6396\n",
      "Epoch 135/1000\n",
      "1500/1500 - 0s - loss: 0.4787 - val_loss: 0.6022\n",
      "Epoch 136/1000\n",
      "1500/1500 - 0s - loss: 0.4833 - val_loss: 0.5526\n",
      "Epoch 137/1000\n",
      "1500/1500 - 0s - loss: 0.4825 - val_loss: 0.5877\n",
      "Epoch 138/1000\n",
      "1500/1500 - 0s - loss: 0.4307 - val_loss: 0.6097\n",
      "Epoch 139/1000\n",
      "1500/1500 - 0s - loss: 0.4671 - val_loss: 0.5203\n",
      "Epoch 140/1000\n",
      "1500/1500 - 0s - loss: 0.4241 - val_loss: 0.5027\n",
      "Epoch 141/1000\n",
      "1500/1500 - 0s - loss: 0.4207 - val_loss: 0.4999\n",
      "Epoch 142/1000\n",
      "1500/1500 - 0s - loss: 0.4303 - val_loss: 0.5028\n",
      "Epoch 143/1000\n",
      "1500/1500 - 0s - loss: 0.4302 - val_loss: 0.5004\n",
      "Epoch 144/1000\n",
      "1500/1500 - 0s - loss: 0.3908 - val_loss: 0.5406\n",
      "Epoch 145/1000\n",
      "1500/1500 - 0s - loss: 0.4050 - val_loss: 0.4945\n",
      "Epoch 146/1000\n",
      "1500/1500 - 0s - loss: 0.4060 - val_loss: 0.5061\n",
      "Epoch 147/1000\n",
      "1500/1500 - 0s - loss: 0.4021 - val_loss: 0.4727\n",
      "Epoch 148/1000\n",
      "1500/1500 - 0s - loss: 0.3822 - val_loss: 0.4726\n",
      "Epoch 149/1000\n",
      "1500/1500 - 0s - loss: 0.3853 - val_loss: 0.4718\n",
      "Epoch 150/1000\n",
      "1500/1500 - 0s - loss: 0.3800 - val_loss: 0.4584\n",
      "Epoch 151/1000\n",
      "1500/1500 - 0s - loss: 0.4064 - val_loss: 0.4819\n",
      "Epoch 152/1000\n",
      "1500/1500 - 0s - loss: 0.3801 - val_loss: 0.4549\n",
      "Epoch 153/1000\n",
      "1500/1500 - 0s - loss: 0.3731 - val_loss: 0.4404\n",
      "Epoch 154/1000\n",
      "1500/1500 - 0s - loss: 0.3758 - val_loss: 0.4543\n",
      "Epoch 155/1000\n",
      "1500/1500 - 0s - loss: 0.3896 - val_loss: 0.4451\n",
      "Epoch 156/1000\n",
      "1500/1500 - 0s - loss: 0.3658 - val_loss: 0.4340\n",
      "Epoch 157/1000\n",
      "1500/1500 - 0s - loss: 0.3549 - val_loss: 0.5411\n",
      "Epoch 158/1000\n",
      "1500/1500 - 0s - loss: 0.4245 - val_loss: 0.5268\n",
      "Epoch 159/1000\n",
      "1500/1500 - 0s - loss: 0.3633 - val_loss: 0.4717\n",
      "Epoch 160/1000\n",
      "1500/1500 - 0s - loss: 0.3497 - val_loss: 0.4348\n",
      "Epoch 161/1000\n",
      "1500/1500 - 0s - loss: 0.3525 - val_loss: 0.4279\n",
      "Epoch 162/1000\n",
      "1500/1500 - 0s - loss: 0.3555 - val_loss: 0.4575\n",
      "Epoch 163/1000\n",
      "1500/1500 - 0s - loss: 0.3509 - val_loss: 0.4234\n",
      "Epoch 164/1000\n",
      "1500/1500 - 0s - loss: 0.3512 - val_loss: 0.4369\n",
      "Epoch 165/1000\n",
      "1500/1500 - 0s - loss: 0.3494 - val_loss: 0.4646\n",
      "Epoch 166/1000\n",
      "1500/1500 - 0s - loss: 0.3424 - val_loss: 0.4349\n",
      "Epoch 167/1000\n",
      "1500/1500 - 0s - loss: 0.4121 - val_loss: 0.4189\n",
      "Epoch 168/1000\n",
      "1500/1500 - 0s - loss: 0.3411 - val_loss: 0.4333\n",
      "Epoch 169/1000\n",
      "1500/1500 - 0s - loss: 0.3416 - val_loss: 0.4226\n",
      "Epoch 170/1000\n",
      "1500/1500 - 0s - loss: 0.3271 - val_loss: 0.4271\n",
      "Epoch 171/1000\n",
      "1500/1500 - 0s - loss: 0.3256 - val_loss: 0.4146\n",
      "Epoch 172/1000\n",
      "1500/1500 - 0s - loss: 0.3427 - val_loss: 0.4122\n",
      "Epoch 173/1000\n",
      "1500/1500 - 0s - loss: 0.3359 - val_loss: 0.4366\n",
      "Epoch 174/1000\n",
      "1500/1500 - 0s - loss: 0.3405 - val_loss: 0.4238\n",
      "Epoch 175/1000\n",
      "1500/1500 - 0s - loss: 0.3566 - val_loss: 0.4179\n",
      "Epoch 176/1000\n",
      "1500/1500 - 0s - loss: 0.3465 - val_loss: 0.4907\n",
      "Epoch 177/1000\n",
      "1500/1500 - 0s - loss: 0.3373 - val_loss: 0.5647\n",
      "Epoch 00177: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error\n",
    "\n",
    "The mean square error is the sum of the squared differences between the prediction ($\\hat{y}$) and the expected ($y$).  MSE values are not of a particular unit.  If an MSE value has decreased for a model, that is good.  However, beyond this, there is not much more you can determine.  Low MSE values are desired.\n",
    "\n",
    "$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.41223663539893457\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure MSE error.  \n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error\n",
    "\n",
    "The root mean square (RMSE) is essentially the square root of the MSE.  Because of this, the RMSE error is in the same units as the training data outcome. Low RMSE values are desired.\n",
    "\n",
    "$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.6420565671332508\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Chart\n",
    "\n",
    "\n",
    "To generate a lift chart, perform the following activities:\n",
    "\n",
    "* Sort the data by expected output. Plot the blue line above.\n",
    "* For every point on the x-axis plot the predicted value for that same data point. This is the green line above.\n",
    "* The x-axis is just 0 to 100% of the dataset. The expected always starts low and ends high.\n",
    "* The y-axis is ranged according to the values predicted.\n",
    "\n",
    "Reading a lift chart:\n",
    "\n",
    "* The expected and predict lines should be close. Notice where one is above the ot other.\n",
    "* The above chart is the most accurate on lower MPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4.4: Training Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Backpropagation\n",
    "Backpropagation is the primary means by which a neural network's weights are determined during training. Backpropagation works by calculating a weight change amount ($v_t$) for every weight($\\theta$, theata) in the neural network.  This value is subtracted from every weight by the following equation: \n",
    "\n",
    "$ \\theta_t = \\theta_{t-1} - v_t $\n",
    "\n",
    "This process is repeated for every iteration($t$).  How the weight change is calculated depends on the training algorithm.  Classic backpropagation simply calculates a gradient ($\\nabla$, nabla) for every weight in the neural network with respect to the error function ($J$) of the neural network.  The gradient is scaled by a learning rate ($\\eta$, eta).\n",
    "\n",
    "$ v_t = \\eta \\nabla_{\\theta_{t-1}} J(\\theta_{t-1}) $\n",
    "\n",
    "The learning rate is an important concept for backpropagation training.  Setting the learning rate can be complex:\n",
    "\n",
    "* Too low of a learning rate will usually converge to a good solution; however, the process will be very slow.\n",
    "* Too high of a learning rate will either fail outright, or converge to a higher error than a better learning rate.\n",
    "\n",
    "Common values for learning rate are: 0.1, 0.01, 0.001, etc.\n",
    "\n",
    "Gradients:\n",
    "\n",
    "![Derivative](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_2_deriv.png \"Derivative\")\n",
    "\n",
    "The following link, from the book, shows how a simple [neural network is trained with backpropagation](http://www.heatonresearch.com/aifh/vol3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Backpropagation\n",
    "\n",
    "Momentum adds another term to the calculation of $v_t$:\n",
    "\n",
    "$ v_t = \\eta \\nabla_{\\theta_{t-1}} J(\\theta_{t-1}) + \\lambda v_{t-1} $\n",
    "\n",
    "Like the learning rate, momentum adds another training parameter that scales the effect of momentum.  Momentum backpropagation has two training parameters: learning rate ($\\eta$, eta) and momentum ($\\lambda$, lambda).  Momentum simply adds the scaled value of the previous weight change amount ($v_{t-1}$) to the current weight change amount($v_t$).\n",
    "\n",
    "This has the effect of adding additional force behind a direction a weight was moving.  This might allow the weight to escape a local minima:\n",
    "\n",
    "![Momentum](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_5_momentum.png \"Momentum\")\n",
    "\n",
    "A very common value for momentum is 0.9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Online Backpropagation\n",
    "\n",
    "How often should the weights of a neural network be updated?  Gradients can be calculated for a training set element.  These gradients can also be summed together into batches and the weights updated once per batch.\n",
    "\n",
    "* **Online Training** - Update the weights based on gradients calculated from a single training set element.\n",
    "* **Batch Training** - Update the weights based on the sum of the gradients over all training set elements.\n",
    "* **Batch Size** - Update the weights based on the sum of some batch size of training set elements.\n",
    "* **Mini-Batch Training** - The same as batch size, but with a very small batch size.  Mini-batches are very popular and they are often in the 32-64 element range.\n",
    "\n",
    "Because the batch size is smaller than the complete training set size, it may take several batches to make it completely through the training set.  \n",
    "\n",
    "* **Step/Iteration** - The number of batches that were processed.\n",
    "* **Epoch** - The number of times the complete training set was processed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "Stochastic gradient descent (SGD) is currently one of the most popular neural network training algorithms.  It works very similarly to Batch/Mini-Batch training, except that the batches are made up of a random set of training elements.\n",
    "\n",
    "This leads to a very irregular convergence in error during training:\n",
    "\n",
    "![SGD Error](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_5_sgd_error.png \"SGD Error\")\n",
    "[Image from Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "Because the neural network is trained on a random sample of the complete training set each time, the error does not make a smooth transition downward.  However, the error usually does go down.\n",
    "\n",
    "Advantages to SGD include:\n",
    "\n",
    "* Computationally efficient.  Even with a very large training set, each training step can be relatively fast.\n",
    "* Decreases overfitting by focusing on only a portion of the training set each step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Techniques\n",
    "\n",
    "One problem with simple backpropagation training algorithms is that they are highly sensative to learning rate and momentum.  This is difficult because:\n",
    "\n",
    "* Learning rate must be adjusted to a small enough level to train an accurate neural network.\n",
    "* Momentum must be large enough to overcome local minima, yet small enough to not destabilize the training.\n",
    "* A single learning rate/momentum is often not good enough for the entire training process. It is often useful to automatically decrease learning rate as the training progresses.\n",
    "* All weights share a single learning rate/momentum.\n",
    "\n",
    "Other training techniques:\n",
    "\n",
    "* **Resilient Propagation** - Use only the magnitude of the gradient and allow each neuron to learn at its own rate.  No need for learning rate/momentum; however, only works in full batch mode.\n",
    "* **Nesterov accelerated gradient** - Helps mitigate the risk of choosing a bad mini-batch.\n",
    "* **Adagrad** - Allows an automatically decaying per-weight learning rate and momentum concept.\n",
    "* **Adadelta** - Extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate.\n",
    "* **Non-Gradient Methods** - Non-gradient methods can *sometimes* be useful, though rarely outperform gradient-based backpropagation methods.  These include: [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing), [genetic algorithms](https://en.wikipedia.org/wiki/Genetic_algorithm), [particle swarm optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization), [Nelder Mead](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method), and [many more](https://en.wikipedia.org/wiki/Category:Optimization_algorithms_and_methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM Update\n",
    "\n",
    "ADAM is the first training algorithm you should try.  It is very effective.  Kingma and Ba (2014) introduced the Adam update rule that derives its name from the adaptive moment estimates that it uses.  Adam estimates the first (mean) and second (variance) moments to determine the weight corrections.  Adam begins with an exponentially decaying average of past gradients (m):\n",
    "\n",
    "$ m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t $\n",
    "\n",
    "This average accomplishes a similar goal as classic momentum update; however, its value is calculated automatically based on the current gradient ($g_t$).  The update rule then calculates the second moment ($v_t$):\n",
    "\n",
    "$ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 $\n",
    "\n",
    "The values $m_t$ and $v_t$ are estimates of the first moment (the mean) and the second moment (the uncentered variance) of the gradients respectively.  However, they will have a strong bias towards zero in the initial training cycles.  The first moment’s bias is corrected as follows.\n",
    "\n",
    "$ \\hat{m}_t = \\frac{m_t}{1-\\beta^t_1} $\n",
    "\n",
    "Similarly, the second moment is also corrected:\n",
    "\n",
    "$ \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t} $\n",
    "\n",
    "These bias-corrected first and second moment estimates are applied to the ultimate Adam update rule, as follows:\n",
    "\n",
    "$ \\theta_t = \\theta_{t-1} - \\frac{\\alpha \\cdot \\hat{m}_t}{\\sqrt{\\hat{v}_t}+\\eta} \\hat{m}_t $\n",
    "\n",
    "Adam is very tolerant to initial learning rate (\\alpha) and other training parameters. Kingma and Ba (2014)  propose default values of 0.9 for $\\beta_1$, 0.999 for $\\beta_2$, and 10-8 for $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods Compared\n",
    "\n",
    "The following image shows how each of these algorithms train (image credits: [author](Alec Radford), [where I found it](http://sebastianruder.com/optimizing-gradient-descent/index.html#visualizationofalgorithms) ):\n",
    "\n",
    "![Training Techniques](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/contours_evaluation_optimizers.gif \"Training Techniques\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the Update Rule in Tensorflow\n",
    "\n",
    "TensorFlow allows the update rule to be set to one of:\n",
    "\n",
    "* Adagrad\n",
    "* **Adam**\n",
    "* Ftrl\n",
    "* Momentum\n",
    "* RMSProp\n",
    "* **SGD**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00128: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values\n",
    "\n",
    "# Create train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam') # Modify here\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=1000)\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4.5: Error Calculation from Scratch\n",
    "\n",
    "We will now look at how to calculate RMSE and logloss by hand.  \n",
    "\n",
    "\n",
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (MSE): 0.14200000000000007\n",
      "Score (RMSE): 0.37682887362833556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "predicted = [1.1,1.9,3.4,4.2,4.3]\n",
    "expected = [1,2,3,4,5]\n",
    "\n",
    "score_mse = metrics.mean_squared_error(predicted,expected)\n",
    "score_rmse = np.sqrt(score_mse)\n",
    "print(\"Score (MSE): {}\".format(score_mse))\n",
    "print(\"Score (RMSE): {}\".format(score_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (MSE): 0.14200000000000007\n",
      "Score (RMSE): 0.37682887362833556\n"
     ]
    }
   ],
   "source": [
    "score_mse = ((predicted[0]-expected[0])**2 + (predicted[1]-expected[1])**2 \n",
    "+ (predicted[2]-expected[2])**2 + (predicted[3]-expected[3])**2\n",
    "+ (predicted[4]-expected[4])**2)/len(predicted)\n",
    "score_rmse = np.sqrt(score_mse)\n",
    "    \n",
    "print(\"Score (MSE): {}\".format(score_mse))\n",
    "print(\"Score (RMSE): {}\".format(score_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "We will now look at how to calculate a logloss by hand. For this we look at a binary prediction. The expected is always 0 or 1. The predicted is some number between 0-1 that indicates the probability true (1). Therefore, a prediction of 1.0 is completely correct if the expected is 1 and completely wrong if the expected is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06678801305495843\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "expected = [1,1,0,0,0]\n",
    "predicted = [0.9,0.99,0.1,0.05,0.06]\n",
    "\n",
    "print(metrics.log_loss(expected,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attempt to calculate the same logloss manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Logloss 0.06678801305495843\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "score_logloss = (np.log(1.0-np.abs(expected[0]-predicted[0]))+\\\n",
    "np.log(1.0-np.abs(expected[1]-predicted[1]))+\\\n",
    "np.log(1.0-np.abs(expected[2]-predicted[2]))+\\\n",
    "np.log(1.0-np.abs(expected[3]-predicted[3]))+\\\n",
    "np.log(1.0-np.abs(expected[4]-predicted[4])))\\\n",
    "*(-1/len(predicted))\n",
    "\n",
    "print(f'Score Logloss {score_logloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 4 Assignment\n",
    "\n",
    "You can find the first assignment here: [assignment 4](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-2.0)",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
