{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXSZ9CRGevw0"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 10: Time Series in Keras**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LFASLt5evw2"
   },
   "source": [
    "# Module Video Material\n",
    "\n",
    "Main video lecture:\n",
    "\n",
    "* [Part 10.1: Time Series Data Encoding for Deep Learning, TensorFlow and Keras](https://www.youtube.com/watch?v=X72l3HIt8ro&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=29)\n",
    "* [Part 10.2: Programming LSTM with Keras and TensorFlow](https://www.youtube.com/watch?v=hRDfQGbqJJQ&index=30&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 10.3: Image Captioning with Keras and TensorFlow](https://www.youtube.com/watch?v=UnclHXZszpw&index=31&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 10.4: Temporal CNN in Keras and TensorFlow](https://www.youtube.com/watch?v=UnclHXZszpw&index=31&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 10.5: Predicting the Stock Market with Keras and TensorFlow](https://www.youtube.com/watch?v=UnclHXZszpw&index=31&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xH2XSZmevxx"
   },
   "source": [
    "# Part 10.3: Image Captioning with Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhFafQrWS0pw"
   },
   "source": [
    "\n",
    "* [Andrej Karpathys Dissertation](https://cs.stanford.edu/people/karpathy/main.pdf)\n",
    "\n",
    "* [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* [Image Capturing with Keras](https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m2p8iXQygqRN",
    "outputId": "f4c7a9d6-7662-4f3c-b922-16f2cabe0706"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import glob\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import tensorflow.keras.applications.mobilenet  \n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import keras.applications.inception_v3\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import keras.preprocessing.image\n",
    "import pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.merge import add\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "START = \"startseq\"\n",
    "STOP = \"endseq\"\n",
    "EPOCHS = 10\n",
    "USE_INCEPTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGt4swcqIFKR"
   },
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "2W5oWBSofR7d",
    "outputId": "e60b4ad2-bf78-49f0-b1c6-51d1f674e101"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj4K-WHafser"
   },
   "outputs": [],
   "source": [
    "root_captioning = \"/content/drive/My Drive/projects/captions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ra-d7BLlf1nC"
   },
   "outputs": [],
   "source": [
    "null_punct = str.maketrans('', '', string.punctuation)\n",
    "lookup = dict()\n",
    "\n",
    "with open( os.path.join(root_captioning,'Flickr8k_text','Flickr8k.token.txt'), 'r') as fp:\n",
    "  \n",
    "  max_length = 0\n",
    "  for line in fp.read().split('\\n'):\n",
    "    tok = line.split()\n",
    "    if len(line) >= 2:\n",
    "      id = tok[0].split('.')[0]\n",
    "      desc = tok[1:]\n",
    "      \n",
    "      # Cleanup description\n",
    "      desc = [word.lower() for word in desc]\n",
    "      desc = [w.translate(null_punct) for w in desc]\n",
    "      desc = [word for word in desc if len(word)>1]\n",
    "      desc = [word for word in desc if word.isalpha()]\n",
    "      max_length = max(max_length,len(desc))\n",
    "      \n",
    "      if id not in lookup:\n",
    "        lookup[id] = list()\n",
    "      lookup[id].append(' '.join(desc))\n",
    "      \n",
    "lex = set()\n",
    "for key in lookup:\n",
    "  [lex.update(d.split()) for d in lookup[key]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Gnq3ZjaSU79-",
    "outputId": "03cfaed4-086f-4e21-e96b-3246f8f90383"
   },
   "outputs": [],
   "source": [
    "print(len(lookup))\n",
    "print(len(lex))\n",
    "print(max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYVZ83DLsb1r"
   },
   "outputs": [],
   "source": [
    "# Warning, running this too soon on GDrive can sometimes not work.\n",
    "# Just rerun if len(img) = 0\n",
    "img = glob.glob(os.path.join(root_captioning,'Flicker8k_Dataset', '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DosvCz6bVZA7",
    "outputId": "a33aa090-71ca-4e20-a1ff-93bb5716d182"
   },
   "outputs": [],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhJSo7czkW03"
   },
   "outputs": [],
   "source": [
    "train_images_path = os.path.join(root_captioning,'Flickr8k_text','Flickr_8k.trainImages.txt') \n",
    "train_images = set(open(train_images_path, 'r').read().strip().split('\\n'))\n",
    "test_images_path = os.path.join(root_captioning,'Flickr8k_text','Flickr_8k.testImages.txt') \n",
    "test_images = set(open(test_images_path, 'r').read().strip().split('\\n'))\n",
    "\n",
    "train_img = []\n",
    "test_img = []\n",
    "\n",
    "for i in img:\n",
    "  f = os.path.split(i)[-1]\n",
    "  if f in train_images: \n",
    "    train_img.append(f) \n",
    "  elif f in test_images:\n",
    "    test_img.append(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ZZQZkT8X_qNt",
    "outputId": "fe39a09b-6f99-4f3a-a709-c31476d25956"
   },
   "outputs": [],
   "source": [
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "print(len(lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBX6TJbPF0nD"
   },
   "outputs": [],
   "source": [
    "train_descriptions = {k:v for k,v in lookup.items() if f'{k}.jpg' in train_images}\n",
    "for n,v in train_descriptions.items(): \n",
    "  for d in range(len(v)):\n",
    "    v[d] = f'{START} {v[d]} {STOP}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v3_PCjddHcUe",
    "outputId": "f62157a9-f954-4940-b947-f195f9279674"
   },
   "outputs": [],
   "source": [
    "len(train_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "DWOP58lrtGwt",
    "outputId": "c24ba9c1-7371-4ef2-9188-f57cded0d482"
   },
   "outputs": [],
   "source": [
    "if USE_INCEPTION:\n",
    "  encode_model = InceptionV3(weights='imagenet')\n",
    "  encode_model = Model(encode_model.input, encode_model.layers[-2].output)\n",
    "  WIDTH = 299\n",
    "  HEIGHT = 299\n",
    "  OUTPUT_DIM = 2048\n",
    "  preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "else:\n",
    "  encode_model = MobileNet(weights='imagenet',include_top=False)\n",
    "  WIDTH = 224\n",
    "  HEIGHT = 224\n",
    "  OUTPUT_DIM = 50176\n",
    "  preprocess_input = keras.applications.mobilenet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_QQ-D9Rq9SwF",
    "outputId": "56bcbacd-bf69-4537-a093-e19fe42edf93"
   },
   "outputs": [],
   "source": [
    "encode_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SeT4zJ8l9Ps9"
   },
   "outputs": [],
   "source": [
    "def encodeImage(img):\n",
    "  img = img.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
    "  x = keras.preprocessing.image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  x = encode_model.predict(x) # Get the encoding vector for the image\n",
    "  x = np.reshape(x, OUTPUT_DIM )\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfusVb6uKREw"
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(root_captioning,\"data\",f'train{OUTPUT_DIM}.pkl')\n",
    "if not os.path.exists(train_path):\n",
    "  start = time()\n",
    "  encoding_train = {}\n",
    "  for id in tqdm(train_img):\n",
    "    image_path = os.path.join(root_captioning,'Flicker8k_Dataset', id)\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=(HEIGHT, WIDTH))\n",
    "    encoding_train[id] = encodeImage(img)\n",
    "  with open(train_path, \"wb\") as fp:\n",
    "    pickle.dump(encoding_train, fp)\n",
    "  print(f\"\\nGenerating training set took: {hms_string(time()-start)}\")\n",
    "else:\n",
    "  with open(train_path, \"rb\") as fp:\n",
    "    encoding_train = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mO2cNDOP64-"
   },
   "outputs": [],
   "source": [
    "test_path = os.path.join(root_captioning,\"data\",f'test{OUTPUT_DIM}.pkl')\n",
    "if not os.path.exists(test_path):\n",
    "  start = time()\n",
    "  encoding_test = {}\n",
    "  for id in tqdm(test_img):\n",
    "    image_path = os.path.join(root_captioning,'Flicker8k_Dataset', id)\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=(HEIGHT, WIDTH))\n",
    "    encoding_test[id] = encodeImage(img)\n",
    "  with open(test_path, \"wb\") as fp:\n",
    "    pickle.dump(encoding_test, fp)\n",
    "  print(f\"\\nGenerating testing set took: {hms_string(time()-start)}\")\n",
    "else:\n",
    "  with open(test_path, \"rb\") as fp:\n",
    "    encoding_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C8DFzzPmXg-n",
    "outputId": "aa2f5275-c158-4c41-b1a8-2e3c9bcf4e4e"
   },
   "outputs": [],
   "source": [
    "all_train_captions = []\n",
    "for key, val in train_descriptions.items():\n",
    "    for cap in val:\n",
    "        all_train_captions.append(cap)\n",
    "len(all_train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-HxHSgLgYUUE",
    "outputId": "cf26250e-255f-4599-eaae-7ee13e09cb8c"
   },
   "outputs": [],
   "source": [
    "word_count_threshold = 10\n",
    "word_counts = {}\n",
    "nsents = 0\n",
    "for sent in all_train_captions:\n",
    "    nsents += 1\n",
    "    for w in sent.split(' '):\n",
    "        word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Oi3zqAUhYcNP",
    "outputId": "32e046c9-e20f-4d41-a470-94ad764a34a3"
   },
   "outputs": [],
   "source": [
    "idxtoword = {}\n",
    "wordtoidx = {}\n",
    "\n",
    "ix = 1\n",
    "for w in vocab:\n",
    "    wordtoidx[w] = ix\n",
    "    idxtoword[ix] = w\n",
    "    ix += 1\n",
    "    \n",
    "vocab_size = len(idxtoword) + 1 \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KSohY53bYjTi",
    "outputId": "1d88d063-000a-4532-d043-173927ba87d3"
   },
   "outputs": [],
   "source": [
    "max_length +=2\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZsbbCx6d04X"
   },
   "outputs": [],
   "source": [
    "def data_generator(descriptions, photos, wordtoidx, max_length, num_photos_per_batch):\n",
    "    x1, x2, y = [], [], []\n",
    "    n=0\n",
    "    while 1:\n",
    "        for key, desc_list in descriptions.items():\n",
    "            n+=1\n",
    "            photo = photos[key+'.jpg']\n",
    "            for desc in desc_list:\n",
    "                seq = [wordtoidx[word] for word in desc.split(' ') if word in wordtoidx]\n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    x1.append(photo)\n",
    "                    x2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            if n==num_photos_per_batch:\n",
    "                yield [[np.array(x1), np.array(x2)], np.array(y)]\n",
    "                1, x2, y = [], [], []\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IY_9XZ4Hec73",
    "outputId": "4287220c-365e-477f-9ae9-0b428b36573c"
   },
   "outputs": [],
   "source": [
    "glove_dir = os.path.join(root_captioning,'glove.6B')\n",
    "embeddings_index = {} \n",
    "f = open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adEmnYFEfog6"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "\n",
    "# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in wordtoidx.items():\n",
    "    #if i < max_words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in the embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "86hPHHjSfx8p",
    "outputId": "3a23f40f-16f2-4586-a052-c11aabf72438"
   },
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "2homy6Znf7wL",
    "outputId": "7311ce15-c30b-4019-a9b4-efa81891a55a"
   },
   "outputs": [],
   "source": [
    "inputs1 = Input(shape=(OUTPUT_DIM,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "caption_model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UcCe2n5pnGfo",
    "outputId": "3cd8f828-47e1-4c50-9986-2b971353a374"
   },
   "outputs": [],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "asGo7TqRfgJp",
    "outputId": "0bc274cf-3d71-41ae-b7c8-c1985db75bd1"
   },
   "outputs": [],
   "source": [
    "caption_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "gze36nMIfoEg",
    "outputId": "969d84cc-566c-458c-8d67-89fd52eb2972"
   },
   "outputs": [],
   "source": [
    "caption_model.layers[2].set_weights([embedding_matrix])\n",
    "caption_model.layers[2].trainable = False\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LXG3PE5fxzU"
   },
   "outputs": [],
   "source": [
    "number_pics_per_bath = 3\n",
    "steps = len(train_descriptions)//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "dyCHBbjnf2b1",
    "outputId": "6ae667da-a4ab-42d3-86fa-d63e8a93baf0"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(EPOCHS)):\n",
    "    generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
    "    caption_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "HjUaN-QN-awx",
    "outputId": "16314a6f-f718-4c99-bb10-d547fa8ace61"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(EPOCHS)):\n",
    "    generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
    "    caption_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "P2WWA8LWIV1N",
    "outputId": "c66317dc-afc7-4b9e-ddde-3392959d083b"
   },
   "outputs": [],
   "source": [
    "caption_model.optimizer.lr = 0.0001\n",
    "number_pics_per_bath = 6\n",
    "steps = len(train_descriptions)//number_pics_per_bath\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
    "    caption_model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPKINJ3JMbSy"
   },
   "outputs": [],
   "source": [
    "def generateCaption(photo):\n",
    "    in_text = START\n",
    "    for i in range(max_length):\n",
    "        sequence = [wordtoidx[w] for w in in_text.split() if w in wordtoidx]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = caption_model.predict([photo,sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = idxtoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == STOP:\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TtaaQI8wMsst",
    "outputId": "144f952c-cfdc-4836-d69a-c7d0fcea2eab"
   },
   "outputs": [],
   "source": [
    "for z in range(10):\n",
    "  pic = list(encoding_test.keys())[z]\n",
    "  image = encoding_test[pic].reshape((1,OUTPUT_DIM))\n",
    "  print(os.path.join(root_captioning,'Flicker8k_Dataset', pic))\n",
    "  x=plt.imread(os.path.join(root_captioning,'Flicker8k_Dataset', pic))\n",
    "  plt.imshow(x)\n",
    "  plt.show()\n",
    "  print(\"Caption:\",generateCaption(image))\n",
    "  print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a1mncR2JPno-",
    "outputId": "c3b42169-b7ee-422c-811b-19573edfbf60"
   },
   "outputs": [],
   "source": [
    "encoding_test[pic].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "-jl0BUNIMxGv",
    "outputId": "ca122520-7ce1-494f-e319-fe94fa577d59"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-1-96584b1a7fb2>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-96584b1a7fb2>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/about-jeff-heaton-2018.jpg?raw=true\u001b[0m\n\u001b[0m                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "urls = [\n",
    "  \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/2015-03-09-phd-2nd-cluster-visit-1.png?raw=true\",\n",
    "\"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/about-jeff-heaton-2018.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/annie_dog.jpg\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/bread_n_breakfast.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/family_christmas.png\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/github_rock.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory.jpeg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory_coat.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory_exercise.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory_home.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory_n_stuffed.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory_run.jpeg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/hickory_sleep.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/jeff_books.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/jeff_cook.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/jeff_cube.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/jeff_laptop.jpg?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/jeff_laptops.png?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/road.JPG?raw=true\",\n",
    "    \"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/photos/snow_shovel.jpg?raw=true\"\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "  response = requests.get(url)\n",
    "  img = Image.open(BytesIO(response.content))\n",
    "  img.load()\n",
    "\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "  \n",
    "  response = requests.get(url)\n",
    "\n",
    "  img = encodeImage(img).reshape((1,OUTPUT_DIM))\n",
    "  print(img.shape)\n",
    "  print(\"Caption:\",generateCaption(img))\n",
    "  print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eklub-S67c_G"
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "  encode_model = InceptionV3(weights='imagenet')\n",
    "  encode_model = Model(encode_model.input, encode_model.layers[-2].output)\n",
    "  WIDTH = 299\n",
    "  HEIGHT = 299\n",
    "  OUTPUT_DIM = 2048\n",
    "  preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "else:\n",
    "  encode_model = MobileNet(weights='imagenet',include_top=False)\n",
    "  WIDTH = 224\n",
    "  HEIGHT = 224\n",
    "  OUTPUT_DIM = 50176\n",
    "  preprocess_input = keras.applications.mobilenet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK6S1029-chI"
   },
   "outputs": [],
   "source": [
    "def encodeImage(img):\n",
    "  img = img.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
    "  x = keras.preprocessing.image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  x = encode_model.predict(x) # Get the encoding vector for the image\n",
    "  #x = np.reshape(x, OUTPUT_DIM )\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "6q4f9BuW7ePS",
    "outputId": "d6a5a74d-2c2f-4a19-9796-1e212214ad17"
   },
   "outputs": [],
   "source": [
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "OUTPUT_DIM = 1000\n",
    "encode_model = MobileNet(weights='imagenet',include_top=True)\n",
    "encode_model = Model(encode_model.input, encode_model.layers[-5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3WPGUwX-fG2"
   },
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img('/content/drive/My Drive/projects/captions/Flicker8k_Dataset/2301525531_edde12d673.jpg', target_size=(HEIGHT, WIDTH))\n",
    "x = encodeImage(img)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jg2qiUNoDqxN"
   },
   "outputs": [],
   "source": [
    "encode_model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Y0PnEnp7pNo"
   },
   "outputs": [],
   "source": [
    "encode_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "zFZpd0AZevxz"
   },
   "source": [
    "# Module 10 Assignment\n",
    "\n",
    "You can find the first assignment here: [assignment 10](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class10.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of t81_558_class10_3_captioning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
