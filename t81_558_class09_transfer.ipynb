{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 9: Regularization: L1, L2 and Dropout**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Video Material\n",
    "\n",
    "Main video lecture:\n",
    "\n",
    "* [Part 9.1: Introduction to Keras Transfer Learning](https://www.youtube.com/watch?v=xyymDGReKdY&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=26)\n",
    "* [Part 9.2: Popular Pretrained Neural Networks for Keras](https://www.youtube.com/watch?v=CEFcwpBneFo&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=27)\n",
    "* [Part 9.3: Transfer Learning for Computer Vision and Keras](https://www.youtube.com/watch?v=JPqwyuK7bPg&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=28)\n",
    "* [Part 9.4: Transfer Learning for Languages and Keras](https://www.youtube.com/watch?v=JPqwyuK7bPg&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=28)\n",
    "* [Part 9.5: Transfer Learning for Keras Feature Engineering](https://www.youtube.com/watch?v=JPqwyuK7bPg&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9.1: Introduction to Keras Transfer Learning\n",
    "\n",
    "Human beings learn new skills throughout their entire lives.  However, this learning is rarely from scratch.  No matter what task a human is learning, they are most likely drawing on experiences from earlier in life to learn this new skill.  In this way, humans learn much differently than most deep learning projects. \n",
    "\n",
    "At some point, a human being learns to tell the difference between a cat and a dog.  To teach a neural network the difference you would obtain a large quantity of cat pictures and dog pictures.  The neural network would iterate over all of these pictures and train on the differences.  The human child that learned to distinguish between the two animals would probably just need to see a few examples where they were told they were looking at each type of animal.  The human child would use previous knowledge of looking at different living and non-living objects to help make this classification.  The child would already know what sub-objects, such as fur, eyes, ears, noses, tails, and teeth looked like.\n",
    "\n",
    "Transfer learning attempts to teach a neural network by similar means.  Rather than training your neural network from scratch, you begin training with preloaded set of weights. Usually you will simply remove the top-most layers of the pretrained neural network and retrain it with new topmost layers.  The layers remaining from the previous neural network will be locked so that training does not change these weights.  Only the newly added layers will be trained.  This process is summarized in the following figure.\n",
    "\n",
    "![Transfer Learning](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/transfer.png \"Transfer Learning\")\n",
    "\n",
    "It can take a great deal of compute power to train a neural network for a large image dataset.  Google, Facebook, Microsoft, and other tech companies have utilized GPU arrays to train high quality neural networks for a variety of applications.  Transferring these weights into your neural network can save you considerable effort and compute time.  It is unlikely that a pretrained model will exactly fit the application that you seek to implement.  Finding the closest pretrained model and using transfer learning is an important skill for a deep learning engineer.\n",
    "\n",
    "The [imagenet dataset]() has several high quality neural networks fit to it.  In the next parts of this module we will take a much closer look at this data set.  For many image recognition tasks, an imagenet trained neural network can be a great starting point for your own neural networks.\n",
    "\n",
    "### Transfer Learning Example\n",
    "\n",
    "Lets look at an example of where transfer learning could be used to build upon an imagenet neural network.  Microsoft released a website that accepts a picture of a dog and attempts to classify these dogs by breed. The Microsoft dog breed website is provided here: \n",
    "\n",
    "[What breed is that dog?](https://www.bing.com/visualsearch/Microsoft/WhatDog)\n",
    "\n",
    "To do this, it ie necessary to obtain pictures of dogs, labeled according to breed. Such a network could be trained entirely from scratch.  However, it would require a large quantity of breed-labeled pictures.  Transfer learning with imagenet could be very beneficial for a neural network project such as this.  A neural network pre-trained on imagenet would already contain neurons that are able to recognize many subcomponents of the various dog breeds that the neural network had previously seen on the other animal images in imagenet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "dummies = pd.get_dummies(df['species']) # Classification\n",
    "species = dummies.columns\n",
    "y = dummies.values\n",
    "\n",
    "\n",
    "# Build neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this example simple, we are not setting aside a validation set.  The goal of this example is to show how to create a multi-layer neural network and transfer the weights to another.  Next we evaluate the accuracy on the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = model.predict(x)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Training Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the model summary is as expected, we can see the three layers previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained a neural network on the iris dataset the knowledge of this neural network can be transferred to other neural networks.  It is possible to create a new neural network from some or all of the layers of this neural network.  Just to demonstrate the technique, we will create a new neural network that is essentially a clone of the first neural network.  This is done by transferring all of the layers from the original neural network into the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "for layer in model.layers:\n",
    "    model2.add(layer)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we would like to calculate the accuracy of the newly created model.  The in-sample accuracy should be the same as the previous model that the new model is based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = model2.predict(x)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Training Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The in-sample accuracy of the newly created neural network is the same as the original neural network.  We've successfully transferred all of the layers from the original neural network.\n",
    "\n",
    "For this example we are going to train a neural network to classify three new hypothetical flowers that are uncreatively named:\n",
    "\n",
    "* Fake Flower 1\n",
    "* Fake Flower 2\n",
    "* Fake Flower 3\n",
    "* Fake Flower 4\n",
    "\n",
    "We have measurements for samples of these flowers that conform to the predictors contained in the original iris dataset: sepal width, sepal length, petal width, and petal length. For transfer learning to be effective the input for the newly trained neural network most closely conform to the original neural network that we are transferring from. \n",
    "\n",
    "We will strip away the last output layer that contains the softmax activation function that performs this final classification.  A new output layer will be created that will classify the 4 new flowers.  Only the weights in this new layer will be trained.  The first two layers will be marked as non-trainable.  The hope is that the first few layers have learned to abstract the raw input data in a way that is also helpful to the new neural network.\n",
    "\n",
    "This is done by looping over the first few layers and copying them to the new neural network. We output a summary of the new neural network to verify that the previous output layer has been stripped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "for i in range(2):\n",
    "    layer = model.layers[i]\n",
    "    layer.trainable = False\n",
    "    model3.add(layer)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the new neural network we add a 4-neuron classification layer and compile for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(Dense(4,activation='softmax')) # Output\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate some training data for the 4 fake flowers, and train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [2.1,0.9,0.8,1.1], # 1\n",
    "    [2.5,1.2,0.8,1.2],\n",
    "    [1.1,3.1,1.1,1.1], # 2\n",
    "    [0.8,2.2,0.7,1.2],\n",
    "    [1.2,0.7,3.1,1.1], # 3\n",
    "    [1.0,1.1,2.4,0.9],\n",
    "    [0.1,1.1,4.1,1.2], # 4\n",
    "    [1.2,0.8,3.1,0.1],\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [0,0,0,1],\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0],\n",
    "    [0,0,1,0],\n",
    "    [0,1,0,0],\n",
    "    [0,1,0,0],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0],\n",
    "])\n",
    "\n",
    "model3.fit(x,y,verbose=0,epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the in-sample accuracy for the new model, that contains transferred layers from the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = model3.predict(x)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Training Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9.2: Popular Pretrained Neural Networks for Keras\n",
    "\n",
    "The following two sites, among others, can be great starting points to find pretrained models for use in your projects:\n",
    "\n",
    "* [TensorFlow Model Zoo](https://modelzoo.co/)\n",
    "* [Papers with Code](https://paperswithcode.com/)\n",
    "\n",
    "Keras contains built in support for several pretrained models.  The the [complete list](https://keras.io/applications/) can be found in the Keras documentation.\n",
    "\n",
    "### DenseNet\n",
    "\n",
    "The [Dense Convolutional Network (DenseNet)](https://arxiv.org/abs/1608.06993) model is [provided by keras](https://keras.io/applications/#densenet). Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available in Keras.\n",
    "\n",
    "### InceptionResNetV2 and InceptionV3\n",
    "\n",
    "The [Inception ResNet V2](https://arxiv.org/pdf/1512.00567v3.pdf) model is [provided by Keras](https://keras.io/applications/#inceptionresnetv2). A convolutional neural network (CNN) that achieves a new state of the art in terms of accuracy on the ILSVRC image classification benchmark. Inception-ResNet-v2 is a variation of our earlier Inception V3 model which borrows some ideas from Microsoft's ResNet papers.\n",
    "\n",
    "### MobileNet\n",
    "\n",
    "The [MobileNet](https://arxiv.org/abs/1704.04861) model is [provided by Keras].(https://keras.io/applications/#mobilenetv2). Created for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.\n",
    "\n",
    "\n",
    "### MobileNetV2\n",
    "\n",
    "The [MobileNet V2](https://arxiv.org/abs/1801.04381) model is [provided by Keras](https://keras.io/applications/#mobilenetv2). Improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. \n",
    "\n",
    "### NASNet\n",
    "\n",
    "The [NASNet](https://arxiv.org/abs/1707.07012) model is [provided by Keras](https://keras.io/applications/#nasnet). Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (the \"NASNet search space\") which enables transferability. In our experiments, we search for the best convolutional layer (or \"cell\") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, named \"NASNet architecture\". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, NASNet achieves 2.4% error rate, which is state-of-the-art. On ImageNet, NASNet achieves, among the published works, state-of-the-art accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74% top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset.\n",
    "\n",
    "### ResNet, ResNetV2, ResNeXt\n",
    "\n",
    "The [ResNet](https://arxiv.org/abs/1512.03385), [ResNetV2](https://arxiv.org/abs/1603.05027), and [ResNeXt](https://arxiv.org/abs/1611.05431) models are [provided by Keras](https://keras.io/applications/#resnet). Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62% error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: this https URL\n",
    "\n",
    "\n",
    "\n",
    "### VGG16 and VGG19\n",
    "\n",
    "The [VGG16 and VGG19](https://arxiv.org/abs/1409.1556) models are [provided by Keras](https://keras.io/applications/#vgg16). In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.\n",
    "\n",
    "### Xception\n",
    "\n",
    "The [Xception](https://arxiv.org/abs/1610.02357) model is [provided by Keras](https://keras.io/applications/#xception). We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9.3: Transfer Learning for Computer Vision and Keras\n",
    "\n",
    "In this part we will make use of transfer learning to create a simple neural network that can recognize dog breeds.  To keep the example simple, we will only train for a handfull of breeds.  A much more advanced form of this model can be found at the [Microsoft Dog Breed Image Search](https://www.bing.com/visualsearch/Microsoft/WhatDog).\n",
    "\n",
    "To keep computation times to a minimum, we will make use of the MobileNet, which is built into Keras.  We will begin by loading the entire MobileNet and seeing how well it classifies with several test images.  MobileNet can classify 1,000 different images.  We will ultimatly extend it to classify image types that are not in its dataset, in this example 3 dog breeds.  However, we begin by classifying image types amoung those that it was trained on.  Even though our test images were not in its training set, the loaded neural network should be able to classify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by downloading weights for a MobileNet trained for the imagenet dataset.  This will take some time to download the first time you train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(weights='imagenet',include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded network is a Keras neural network, just like those that we've been working with so far.  However, this is a neural network that was trained/engineered on advanced hardware.  Simply looking at the structure of an advanced state-of-the-art neural network can be educational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just examining the above structure, several clues to neural network architecture become evident.\n",
    "\n",
    "Notice how some of the layers have zeros in their number of parameters. Items which are hyperparameters are always zero, nothing about that layer is learned.  The other layers have learnable paramaters that are adjusted as training occurs.  The layer types are all hyperparamaters, Keras will not change a convolution layer to a max pooling layer for you.  However, the layers that have parameters are trained/adjusted by the traning algorithm. Most of the parameters seen above are the weights of the neural network.\n",
    "\n",
    "Some of the parameters are maked as non-trainable.  These cannot be adjusted by the training algorithm.  When we later use transfer learning with this model we will strip off the final layers that classify 1000 items and replace with our 3 dog breed classification layer.  Only our new layers will be trainable, we will mark the existing layers as non-trainable.\n",
    "\n",
    "The Relu activation function is used throught the neural network.  Also batch and dropout normalization are used.  We cannot see the percent used for batch normalization, that might be specified in the origional paper.  Many deep neural networks are pyramid shaped, and this is the case for this one.  This neural network uses and expanding pyramid shape as you can see the neuron/filter counts expand from 32 to 64 to 128 to 256 to 512 and max out at 1,024.\n",
    "\n",
    "We will now use the MobileNet to classify several image URL's below.  You can add additional URL's of your own to see how well the MobileNet can classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras.applications.mobilenet import decode_predictions\n",
    "\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "images = [\n",
    "    \"https://cdn.shopify.com/s/files/1/0712/4751/products/SMA-01_2000x.jpg?v=1537468751\",\n",
    "    \"https://farm2.static.flickr.com/1394/967537586_87b1358ad3.jpg\",\n",
    "    \"https://sites.wustl.edu/jeffheaton/files/2016/07/jheaton_wustl1-262izm5-458x458.jpg\",\n",
    "    \"https://1.bp.blogspot.com/-0vGbvWUrSAA/XP-OurPTA4I/AAAAAAAAgtg/TGx6YiGBEGIMjnViDjvVnYzYp__DJ6I-gCLcBGAs/s320/B%252Bt%2525aMbJQkm3Z50rqput%252BA.jpg\"\n",
    "]\n",
    "\n",
    "\n",
    "def make_square(img):\n",
    "    cols,rows = img.size\n",
    "    \n",
    "    if rows>cols:\n",
    "        pad = (rows-cols)/2\n",
    "        img = img.crop((pad,0,cols,cols))\n",
    "    else:\n",
    "        pad = (cols-rows)/2\n",
    "        img = img.crop((0,pad,rows,rows))\n",
    "    \n",
    "    return img\n",
    "        \n",
    "for url in images:\n",
    "    x = []\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = img.resize((IMAGE_WIDTH,IMAGE_HEIGHT),Image.ANTIALIAS)\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    pred = model.predict(x)\n",
    "    \n",
    "    display(\"___________________________________________________________________________________________\")\n",
    "    display(img)\n",
    "    print(np.argmax(pred,axis=1))\n",
    "\n",
    "    lst = decode_predictions(pred, top=5)\n",
    "    for itm in lst[0]:\n",
    "        print(itm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the neural network is doing quite well.  However, it does not classify me as a \"person\", rather I am classified as a \"suit\".  Similarly, my English Bulldog Hickory is classiified as a \"pug\".  This is likely because I am only providiing a closeup of his face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many applications, MobileNet might be entirely acceptable as an image classifier.  However, if you need to classify very specialized images that are not in the 1,000 image types supported by imagenet, it is necessary to use transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer\n",
    "\n",
    "It is possable to create your own image classification network from scratch.  This would take considerable time and resources.  Just creating a dog breed classifier would require many pictures of dogs, labeled by breed.  By using a pretrained neural network, you are tapping into knowldge already built into the lower layaers of the nerual network.  The transferred layers likely already have some notion of eyes, ears, feet, and fur.  These lower level concepts help to train the neural network to identify dog breeds.\n",
    "\n",
    "Next we reload the MobileNet; however, this time we set the *include_top* parameter to *False*. This instructs Keras to not load the final classification layers.  This is the common mode of operation for transfer learning.  We display a summary to see that the top classification layer is now missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add new top layers to the neural network.  Our final SoftMax layer includes support for 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(1024,activation='relu')(x) \n",
    "preds=Dense(3,activation='softmax')(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we mark the origional MobileNet layers as non-trainable and our new layers as trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the neural network we must create a directory structure to hold the images.  The Keras command **flow_from_directory** performs this for us.  It requires that a folder be laid out as follows:\n",
    "\n",
    "image\n",
    "\n",
    "Each class is a folder that contains images of that class.  We can also specify a target size, in this case the origional MobileNet size of 224x224 is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('/Users/jheaton/Downloads/trans', \n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=1,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to compile and fit the neural network.  Notice we are using **fit_generator** rather than **fit**.  This is because we are using the convienent **ImageDataGenerator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to see how our new model can predict dog breeds.  The URLs in the code below provide several example dogs to look at.  Feel free to add your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras.applications.mobilenet import decode_predictions\n",
    "\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "images = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/02.Owczarek_niemiecki_u%C5%BCytkowy_kr%C3%B3tkow%C5%82osy_suka.jpg/2560px-02.Owczarek_niemiecki_u%C5%BCytkowy_kr%C3%B3tkow%C5%82osy_suka.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/5/51/DSHwiki.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Axel%2C_the_English_Bulldog.jpg/440px-Axel%2C_the_English_Bulldog.jpg\",\n",
    "    \"https://1.bp.blogspot.com/-0vGbvWUrSAA/XP-OurPTA4I/AAAAAAAAgtg/TGx6YiGBEGIMjnViDjvVnYzYp__DJ6I-gCLcBGAs/s320/B%252Bt%2525aMbJQkm3Z50rqput%252BA.jpg\",\n",
    "    \"https://thehappypuppysite.com/wp-content/uploads/2017/12/poodle1.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Pudel_Grossschwarz.jpg/440px-Pudel_Grossschwarz.jpg\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "def make_square(img):\n",
    "    cols,rows = img.size\n",
    "    \n",
    "    if rows>cols:\n",
    "        pad = (rows-cols)/2\n",
    "        img = img.crop((pad,0,cols,cols))\n",
    "    else:\n",
    "        pad = (cols-rows)/2\n",
    "        img = img.crop((0,pad,rows,rows))\n",
    "    \n",
    "    return img\n",
    "        \n",
    "for url in images:\n",
    "    x = []\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = img.resize((IMAGE_WIDTH,IMAGE_HEIGHT),Image.ANTIALIAS)\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    pred = model.predict(x)\n",
    "    \n",
    "    display(\"___________________________________________________________________________________________\")\n",
    "    display(img)\n",
    "    print(np.argmax(pred,axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9.4: Transfer Learning for Languages and Keras\n",
    "\n",
    "Transfer learning is commonly used with Natural Language Processing (NLP).  This course has an entire module that covers NLP.  However, for now we will look how a NLP network can be loaded into Keras for transfer learning.  The following three sources were helpful for the creation of this section.\n",
    "\n",
    "* Cer, D., Yang, Y., Kong, S. Y., Hua, N., Limtiaco, N., John, R. S., ... & Sung, Y. H. (2018). [Universal sentence encoder](https://arxiv.org/abs/1803.11175). arXiv preprint arXiv:1803.11175.\n",
    "* [Deep Transfer Learning for Natural Language Processing — Text Classification with Universal Embeddings](https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9)\n",
    "* [Keras Tutorial - How to Use Google's Universal Sentence Encoder for Spam Classification](http://hunterheidenreich.com/blog/google-universal-sentence-encoder-in-keras/)\n",
    "\n",
    "These examples make use of TensorFlow Hub, which allows pretrained models to easily be loaded into TensorFlow.  To install TensorHub use the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also necessary to install TensorFlow Datasets.  This can be done with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_text_classification.ipynb#scrollTo=2ew7HTbPpCJH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Internet Movie DataBase (IMDB) reviews data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
    "                                  batch_size=-1, as_supervised=True)\n",
    "\n",
    "train_examples, train_labels = tfds.as_numpy(train_data)\n",
    "test_examples, test_labels = tfds.as_numpy(test_data)\n",
    "\n",
    "# /Users/jheaton/tensorflow_datasets/imdb_reviews/plain_text/0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pretrained embedding model called [gnews-swivel-20dim](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1).  This was trained by Google on gnews data and can convert RAW text into vectors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following 3 movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b\"I absolutely LOVED this movie when I was a kid. I cried every time I watched it. It wasn't weird to me. I totally identified with the characters. I would love to see it again (and hope I wont be disappointed!). Pufnstuf rocks!!!! I was really drawn in to the fantasy world. And to me the movie was loooong. I wonder if I ever saw the series and have confused them? The acting I thought was strong. I loved Jack Wilde. He was so dreamy to an 10 year old (when I first saw the movie, not in 1970. I can still remember the characters vividly. The flute was totally believable and I can still 'feel' the evil woods. Witchy poo was scary - I wouldn't want to cross her path.\",\n",
       "       b'A very close and sharp discription of the bubbling and dynamic emotional world of specialy one 18year old guy, that makes his first experiences in his gay love to an other boy, during an vacation with a part of his family.<br /><br />I liked this film because of his extremly clear and surrogated storytelling , with all this \"Sound-close-ups\" and quiet moments wich had been full of intensive moods.<br /><br />',\n",
       "       b\"As a lifelong fan of Dickens, I have invariably been disappointed by adaptations of his novels.<br /><br />Although his works presented an extremely accurate re-telling of human life at every level in Victorian Britain, throughout them all was a pervasive thread of humour that could be both playful or sarcastic as the narrative dictated. In a way, he was a literary caricaturist and cartoonist. He could be serious and hilarious in the same sentence. He pricked pride, lampooned arrogance, celebrated modesty, and empathised with loneliness and poverty. It may be a clich\\xc3\\xa9, but he was a people's writer.<br /><br />And it is the comedy that is so often missing from his interpretations. At the time of writing, Oliver Twist is being dramatised in serial form on BBC television. All of the misery and cruelty is their, but non of the humour, irony, and savage lampoonery. The result is just a dark, dismal experience: the story penned by a journalist rather than a novelist. It's not really Dickens at all.<br /><br />'Oliver!', on the other hand, is much closer to the mark. The mockery of officialdom is perfectly interpreted, from the blustering beadle to the drunken magistrate. The classic stand-off between the beadle and Mr Brownlow, in which the law is described as 'a ass, a idiot' couldn't have been better done. Harry Secombe is an ideal choice.<br /><br />But the blinding cruelty is also there, the callous indifference of the state, the cold, hunger, poverty and loneliness are all presented just as surely as The Master would have wished.<br /><br />And then there is crime. Ron Moody is a treasure as the sleazy Jewish fence, whilst Oliver Reid has Bill Sykes to perfection.<br /><br />Perhaps not surprisingly, Lionel Bart - himself a Jew from London's east-end - takes a liberty with Fagin by re-interpreting him as a much more benign fellow than was Dicken's original. In the novel, he was utterly ruthless, sending some of his own boys to the gallows in order to protect himself (though he was also caught and hanged). Whereas in the movie, he is presented as something of a wayward father-figure, a sort of charitable thief rather than a corrupter of children, the latter being a long-standing anti-semitic sentiment. Otherwise, very few liberties are taken with Dickens's original. All of the most memorable elements are included. Just enough menace and violence is retained to ensure narrative fidelity whilst at the same time allowing for children' sensibilities. Nancy is still beaten to death, Bullseye narrowly escapes drowning, and Bill Sykes gets a faithfully graphic come-uppance.<br /><br />Every song is excellent, though they do incline towards schmaltz. Mark Lester mimes his wonderfully. Both his and my favourite scene is the one in which the world comes alive to 'who will buy'. It's schmaltzy, but it's Dickens through and through.<br /><br />I could go on. I could commend the wonderful set-pieces, the contrast of the rich and poor. There is top-quality acting from more British regulars than you could shake a stick at.<br /><br />I ought to give it 10 points, but I'm feeling more like Scrooge today. Soak it up with your Christmas dinner. No original has been better realised.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer can convert each to 20-number vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=309, shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 2.0660517 , -4.491833  ,  3.6127415 , -0.6699504 , -7.310619  ,\n",
       "        -4.402696  , -4.3286967 ,  2.5536625 ,  5.506356  ,  1.5327201 ,\n",
       "        -4.539875  ,  0.2960692 ,  1.5209124 ,  1.1145658 , -6.6717415 ,\n",
       "         3.1345682 ,  5.0351944 , -2.2035742 , -3.4724264 , -0.7029331 ],\n",
       "       [ 2.2850306 , -1.3994653 ,  1.9646566 , -1.8079202 , -0.3574569 ,\n",
       "        -0.12123204, -0.82485604,  0.20197354,  2.4308808 , -1.8707466 ,\n",
       "        -1.8008713 ,  0.9650812 , -1.3530476 , -0.10591842, -2.7889197 ,\n",
       "         0.69957316,  2.0551753 , -1.6120912 , -2.8612442 , -0.7083347 ],\n",
       "       [ 3.9819887 , -4.4838037 ,  5.177359  , -2.3643482 , -3.2938678 ,\n",
       "        -3.5364532 , -2.4786978 ,  2.5525482 ,  6.688532  , -2.3076782 ,\n",
       "        -1.9807833 ,  1.1315885 , -3.0339816 , -0.7604128 , -5.743445  ,\n",
       "         3.4242578 ,  4.790099  , -4.03061   , -5.992149  , -1.7297493 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_layer(train_examples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add addition layers to attempt to classify the movie reviews as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compile the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_examples[:10000]\n",
    "partial_x_train = train_examples[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 2s 147us/sample - loss: 0.8996 - accuracy: 0.5348 - val_loss: 0.7075 - val_accuracy: 0.5826\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 2s 119us/sample - loss: 0.6725 - accuracy: 0.5999 - val_loss: 0.6488 - val_accuracy: 0.6217\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.6324 - accuracy: 0.6427 - val_loss: 0.6163 - val_accuracy: 0.6603\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.5967 - accuracy: 0.6821 - val_loss: 0.5823 - val_accuracy: 0.6916\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.5579 - accuracy: 0.7186 - val_loss: 0.5474 - val_accuracy: 0.7224\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.5190 - accuracy: 0.7516 - val_loss: 0.5132 - val_accuracy: 0.7492\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.4796 - accuracy: 0.7821 - val_loss: 0.4793 - val_accuracy: 0.7753\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.4418 - accuracy: 0.8053 - val_loss: 0.4487 - val_accuracy: 0.7949\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 2s 113us/sample - loss: 0.4063 - accuracy: 0.8273 - val_loss: 0.4229 - val_accuracy: 0.8092\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.3743 - accuracy: 0.8451 - val_loss: 0.4008 - val_accuracy: 0.8205\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.3456 - accuracy: 0.8601 - val_loss: 0.3800 - val_accuracy: 0.8327\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.3197 - accuracy: 0.8755 - val_loss: 0.3633 - val_accuracy: 0.8409\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.2965 - accuracy: 0.8875 - val_loss: 0.3495 - val_accuracy: 0.8485\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 2s 113us/sample - loss: 0.2761 - accuracy: 0.8965 - val_loss: 0.3392 - val_accuracy: 0.8539\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.2579 - accuracy: 0.9032 - val_loss: 0.3278 - val_accuracy: 0.8604\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.2410 - accuracy: 0.9104 - val_loss: 0.3205 - val_accuracy: 0.8630\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.2260 - accuracy: 0.9167 - val_loss: 0.3141 - val_accuracy: 0.8652\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.2122 - accuracy: 0.9242 - val_loss: 0.3083 - val_accuracy: 0.8685\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.1999 - accuracy: 0.9293 - val_loss: 0.3051 - val_accuracy: 0.8726\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.1878 - accuracy: 0.9353 - val_loss: 0.3012 - val_accuracy: 0.8726\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.1759 - accuracy: 0.9399 - val_loss: 0.3008 - val_accuracy: 0.8749\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.1668 - accuracy: 0.9432 - val_loss: 0.2976 - val_accuracy: 0.8762\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.1543 - accuracy: 0.9485 - val_loss: 0.2997 - val_accuracy: 0.8753\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.1452 - accuracy: 0.9529 - val_loss: 0.2975 - val_accuracy: 0.8776\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 2s 117us/sample - loss: 0.1363 - accuracy: 0.9566 - val_loss: 0.2984 - val_accuracy: 0.8781\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 2s 118us/sample - loss: 0.1278 - accuracy: 0.9591 - val_loss: 0.3004 - val_accuracy: 0.8780\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.1198 - accuracy: 0.9632 - val_loss: 0.3025 - val_accuracy: 0.8773\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 2s 117us/sample - loss: 0.1126 - accuracy: 0.9658 - val_loss: 0.3116 - val_accuracy: 0.8751\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.1065 - accuracy: 0.9688 - val_loss: 0.3142 - val_accuracy: 0.8741\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.0991 - accuracy: 0.9723 - val_loss: 0.3125 - val_accuracy: 0.8766\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.0927 - accuracy: 0.9753 - val_loss: 0.3163 - val_accuracy: 0.8758\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 2s 117us/sample - loss: 0.0870 - accuracy: 0.9783 - val_loss: 0.3208 - val_accuracy: 0.8752\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.0813 - accuracy: 0.9807 - val_loss: 0.3257 - val_accuracy: 0.8743\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.0759 - accuracy: 0.9828 - val_loss: 0.3327 - val_accuracy: 0.8747\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.0710 - accuracy: 0.9845 - val_loss: 0.3385 - val_accuracy: 0.8739\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.0665 - accuracy: 0.9864 - val_loss: 0.3430 - val_accuracy: 0.8735\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 2s 116us/sample - loss: 0.0616 - accuracy: 0.9879 - val_loss: 0.3510 - val_accuracy: 0.8719\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.0573 - accuracy: 0.9893 - val_loss: 0.3625 - val_accuracy: 0.8711\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 2s 117us/sample - loss: 0.0542 - accuracy: 0.9891 - val_loss: 0.3702 - val_accuracy: 0.8706\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.0498 - accuracy: 0.9915 - val_loss: 0.3727 - val_accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 116us/sample - loss: 0.4037 - accuracy: 0.8580\n",
      "[0.4036788517403603, 0.85804]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9.5: Transfer Learning for Keras Feature Engineering\n",
    "\n",
    "http://cs231n.github.io/transfer-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jheaton/miniconda3/envs/tensorflow-2.0/lib/python3.6/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'___________________________________________________________________________________________'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0xB37598710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 1024)\n",
      "[[[[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.26743937 0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 6.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 5.2920284  0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.36230087 0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    1.6294484 ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.5092087 ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    1.1348662 ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    3.2059884 ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras.applications.mobilenet import decode_predictions\n",
    "\n",
    "model = MobileNet(weights='imagenet',include_top=False)\n",
    "\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "images = [\n",
    "    \"https://cdn.shopify.com/s/files/1/0712/4751/products/SMA-01_2000x.jpg?v=1537468751\"\n",
    "]\n",
    "\n",
    "\n",
    "def make_square(img):\n",
    "    cols,rows = img.size\n",
    "    \n",
    "    if rows>cols:\n",
    "        pad = (rows-cols)/2\n",
    "        img = img.crop((pad,0,cols,cols))\n",
    "    else:\n",
    "        pad = (cols-rows)/2\n",
    "        img = img.crop((0,pad,rows,rows))\n",
    "    \n",
    "    return img\n",
    "        \n",
    "for url in images:\n",
    "    x = []\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = img.resize((IMAGE_WIDTH,IMAGE_HEIGHT),Image.ANTIALIAS)\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    pred = model.predict(x)\n",
    "    \n",
    "    display(\"___________________________________________________________________________________________\")\n",
    "    display(img)\n",
    "    print(pred.shape)\n",
    "    print(pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 9 Assignment\n",
    "\n",
    "You can find the first assignment here: [assignment 9](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class9.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-2.0)",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
