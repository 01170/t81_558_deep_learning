{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 14: Other Neural Network Techniques**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 14 Video Material\n",
    "\n",
    "* Part 14.1: What is AutoML [[Video]]() [[Notebook]](t81_558_class_14_01_automl.ipynb)\n",
    "* **Part 14.2: Using Denoising AutoEncoders in Keras** [[Video]]() [[Notebook]](t81_558_class_14_02_auto_encode.ipynb)\n",
    "* Part 14.3: Anomaly Detection in Keras [[Video]]() [[Notebook]](t81_558_class_14_03_anomaly.ipynb)\n",
    "* Part 14.4: Training an Intrusion Detection System with KDD99 [[Video]]() [[Notebook]](t81_558_class_14_04_ids_kdd99.ipynb)\n",
    "* Part 14.5: The Deep Learning Technologies I am Excited About [[Video]]() [[Notebook]](t81_558_class_14_05_new_tech.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 14.2: Using Denoising AutoEncoders in Keras\n",
    "\n",
    "# Function Approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "x = np.sort((360 * rng.rand(100, 1)), axis=0)\n",
    "y = np.array([np.sin(x*(np.pi/180.0)).ravel()]).T\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,y,verbose=0,batch_size=len(x),epochs=25000)\n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "print(\"Actual\")\n",
    "print(y[0:5])\n",
    "\n",
    "print(\"Pred\")\n",
    "print(pred[0:5])\n",
    "\n",
    "chart_regression(pred.flatten(),y,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Output Regression\n",
    "\n",
    "Unlike most models, neural networks can provide multiple regression outputs.  This allows a neural network to generate multiple outputs for the same input.  For example, the MPG data set might be trained to predict both MPG and horsepower.  One area that multiple regression outputs can be useful for is auto encoders.  The following diagram shows a multi-regression neural network.  As you can see, there are multiple output neurons.  Usually multiple output neurons are used for classification.  However, in this case it is a regression neural network.\n",
    "\n",
    "![Multi-Output Regression](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_13_multi_output.png \"Multi-Output Regression\")\n",
    "\n",
    "The following program uses a multi-output regression to predict both [sin](https://en.wikipedia.org/wiki/Trigonometric_functions#Sine.2C_cosine_and_tangent) and [cos](https://en.wikipedia.org/wiki/Trigonometric_functions#Sine.2C_cosine_and_tangent) from the same input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "x = np.sort((360 * rng.rand(100, 1)), axis=0)\n",
    "y = np.array([np.pi * np.sin(x*(np.pi/180.0)).ravel(), np.pi * np.cos(x*(np.pi/180.0)).ravel()]).T\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(2)) # Two output neurons\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,y,verbose=0,batch_size=len(x),epochs=25000)\n",
    "\n",
    "\n",
    "# Fit regression DNN model.\n",
    "pred = model.predict(x)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(pred, y))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(\"Predicted:\")\n",
    "print(np.array(pred[20:25]))\n",
    "\n",
    "print(\"Expected:\")\n",
    "print(np.array(y[20:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Auto Encoder\n",
    "\n",
    "An auto encoder is a neural network that has the same number of input neurons as it does outputs.  The hidden layers of the neural network will have fewer neurons than the input/output neurons.  Because there are fewer neurons, the auto-encoder must learn to encode the input to the fewer hidden neurons.  The predictors (x) and output (y) are exactly the same in an auto encoder.  Because of this, auto encoders are said to be unsupervised.  \n",
    "\n",
    "![Simple Auto Encoder](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_13_auto_encode.png \"Simple Auto Encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following program demonstrates a very simple auto encoder that learns to encode a sequence of numbers.  Fewer hidden neurons will make it much more difficult for the auto encoder to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML \n",
    "import tensorflow as tf\n",
    "\n",
    "x = np.array([range(10)]).astype(np.float32)\n",
    "print(x)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(x.shape[1])) # Multiple output neurons\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,x,verbose=0,epochs=1000)\n",
    "\n",
    "pred = model.predict(x)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,x))\n",
    "print(\"Fold score (RMSE): {}\".format(score))\n",
    "np.set_printoptions(suppress=True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encode (single image)\n",
    "\n",
    "We are now ready to build a simple image auto encoder.  The program below learns an effective encoding for the image.  You can see the distortions that occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.optimizers import SGD\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/9/92/Brookings.jpg\"\n",
    "    \n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.load()\n",
    "img = img.resize((128,128), Image.ANTIALIAS)\n",
    "img_array = np.asarray(img)\n",
    "img_array = img_array.flatten()\n",
    "img_array = np.array([ img_array ])\n",
    "img_array = img_array.astype(np.float32)\n",
    "print(img_array.shape[1])\n",
    "print(img_array)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=img_array.shape[1], activation='relu'))\n",
    "model.add(Dense(img_array.shape[1])) # Multiple output neurons\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(img_array,img_array,verbose=0,epochs=20)\n",
    "\n",
    "print(\"Neural network output\")\n",
    "pred = model.predict(img_array)\n",
    "print(pred)\n",
    "print(img_array)\n",
    "cols,rows = img.size\n",
    "img_array2 = pred[0].reshape(rows,cols,3)\n",
    "img_array2 = img_array2.astype(np.uint8)\n",
    "img2 = Image.fromarray(img_array2, 'RGB')\n",
    "img2   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Images\n",
    "\n",
    "When processing several images together it is sometimes important to standardize them.  The following code reads a sequence of images and causes them to all be of the same size and perfectly square.  If the input images are not square, cropping will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#url = \"http://www.heatonresearch.com/images/about-jeff.jpg\"\n",
    "\n",
    "images = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/9/92/Brookings.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/f/ff/WashU_Graham_Chapel.JPG\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/9/9e/SeigleHall.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/a/aa/WUSTLKnight.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/3/32/WashUABhall.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/c/c0/Brown_Hall.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/f/f4/South40.jpg\"    \n",
    "]\n",
    "\n",
    "\n",
    "def make_square(img):\n",
    "    cols,rows = img.size\n",
    "    \n",
    "    if rows>cols:\n",
    "        pad = (rows-cols)/2\n",
    "        img = img.crop((pad,0,cols,cols))\n",
    "    else:\n",
    "        pad = (cols-rows)/2\n",
    "        img = img.crop((0,pad,rows,rows))\n",
    "    \n",
    "    return img\n",
    "    \n",
    "x = [] \n",
    "    \n",
    "for url in images:\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = make_square(img)\n",
    "    img = img.resize((128,128), Image.ANTIALIAS)\n",
    "    print(url)\n",
    "    display(img)\n",
    "    img_array = np.asarray(img)\n",
    "    img_array = img_array.flatten()\n",
    "    img_array = img_array.astype(np.float32)\n",
    "    img_array = (img_array-128)/128\n",
    "    x.append(img_array)\n",
    "    \n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Auto Encoder (multi-image)\n",
    "\n",
    "Auto encoders can learn the same encoding for multiple images.  The following code learns a single encoding for multiple images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML \n",
    "\n",
    "# Fit regression DNN model.\n",
    "print(\"Creating/Training neural network\")\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(x.shape[1])) # Multiple output neurons\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,x,verbose=0,epochs=1000)\n",
    "\n",
    "print(\"Score neural network\")\n",
    "pred = model.predict(x)\n",
    "\n",
    "cols,rows = img.size\n",
    "for i in range(len(pred)):\n",
    "    print(pred[i])\n",
    "    img_array2 = pred[i].reshape(rows,cols,3)\n",
    "    img_array2 = (img_array2*128)+128\n",
    "    img_array2 = img_array2.astype(np.uint8)\n",
    "    img2 = Image.fromarray(img_array2, 'RGB')\n",
    "    display(img2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Noise to an Image\n",
    "\n",
    "Auto encoders can handle noise.  First it is important to see how to add noise to an image.  There are many ways to add such noise.  The following code adds random black squares to the image to produce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def add_noise(a):\n",
    "    a2 = a.copy()\n",
    "    rows = a2.shape[0]\n",
    "    cols = a2.shape[1]\n",
    "    s = int(min(rows,cols)/20) # size of spot is 1/20 of smallest dimension\n",
    "    \n",
    "    for i in range(100):\n",
    "        x = np.random.randint(cols-s)\n",
    "        y = np.random.randint(rows-s)\n",
    "        a2[y:(y+s),x:(x+s)] = 0\n",
    "        \n",
    "    return a2\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/9/92/Brookings.jpg\"\n",
    "#url = \"http://www.heatonresearch.com/images/about-jeff.jpg\"\n",
    "\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.load()\n",
    "\n",
    "img_array = np.asarray(img)\n",
    "rows = img_array.shape[0]\n",
    "cols = img_array.shape[1]\n",
    "\n",
    "print(\"Rows: {}, Cols: {}\".format(rows,cols))\n",
    "\n",
    "# Create new image\n",
    "img2_array = img_array.astype(np.uint8)\n",
    "print(img2_array.shape)\n",
    "img2_array = add_noise(img2_array)\n",
    "img2 = Image.fromarray(img2_array, 'RGB')\n",
    "img2        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder\n",
    "\n",
    "A denoising auto encoder is designed to remove noise from input signals.  To do this the $y$ becomes each image/signal (just like a normal auto encoder), however, the $x$ becomes a version of $y$ with noise added.  Noise is artificially added to the images to produce $x$.  The following code creates 10 noisy version of each of the images.  The network is trained to convert noisy data ($x$) to the origional input ($y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#url = \"http://www.heatonresearch.com/images/about-jeff.jpg\"\n",
    "\n",
    "images = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/9/92/Brookings.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/f/ff/WashU_Graham_Chapel.JPG\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/9/9e/SeigleHall.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/a/aa/WUSTLKnight.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/3/32/WashUABhall.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/c/c0/Brown_Hall.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/f/f4/South40.jpg\"    \n",
    "]\n",
    "\n",
    "\n",
    "def make_square(img):\n",
    "    cols,rows = img.size\n",
    "    \n",
    "    if rows>cols:\n",
    "        pad = (rows-cols)/2\n",
    "        img = img.crop((pad,0,cols,cols))\n",
    "    else:\n",
    "        pad = (cols-rows)/2\n",
    "        img = img.crop((0,pad,rows,rows))\n",
    "    \n",
    "    return img\n",
    "    \n",
    "x = []    \n",
    "y = []\n",
    "loaded_images = []\n",
    "    \n",
    "for url in images:\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = make_square(img)\n",
    "    img = img.resize((128,128), Image.ANTIALIAS)\n",
    "    \n",
    "    loaded_images.append(img)\n",
    "    print(url)\n",
    "    display(img)\n",
    "    for i in range(10):\n",
    "        img_array = np.asarray(img)\n",
    "        img_array_noise = add_noise(img_array)\n",
    "        \n",
    "        img_array = img_array.flatten()\n",
    "        img_array = img_array.astype(np.float32)\n",
    "        img_array = (img_array-128)/128\n",
    "        \n",
    "        img_array_noise = img_array_noise.flatten()\n",
    "        img_array_noise = img_array_noise.astype(np.float32)\n",
    "        img_array_noise = (img_array_noise-128)/128\n",
    "        \n",
    "        x.append(img_array_noise)\n",
    "        y.append(img_array)\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML \n",
    "\n",
    "# Fit regression DNN model.\n",
    "print(\"Creating/Training neural network\")\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(x.shape[1])) # Multiple output neurons\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,y,verbose=1,epochs=20)\n",
    "\n",
    "print(\"Neural network trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(10):\n",
    "    print(\"*** Trial {}\".format(z+1))\n",
    "    \n",
    "    # Choose random image\n",
    "    i = np.random.randint(len(loaded_images))\n",
    "    img = loaded_images[i]\n",
    "    img_array = np.asarray(img)\n",
    "    cols, rows = img.size\n",
    "\n",
    "    # Add noise\n",
    "    img_array_noise = add_noise(img_array)    \n",
    "\n",
    "    #Display noisy image\n",
    "    img2 = img_array_noise.astype(np.uint8)\n",
    "    img2 = Image.fromarray(img2, 'RGB')\n",
    "    print(\"With noise:\")\n",
    "    display(img2)\n",
    "\n",
    "    # Present noisy image to auto encoder\n",
    "    img_array_noise = img_array_noise.flatten()\n",
    "    img_array_noise = img_array_noise.astype(np.float32)\n",
    "    img_array_noise = (img_array_noise-128)/128\n",
    "    img_array_noise = np.array([img_array_noise])\n",
    "    pred = model.predict(img_array_noise)[0]\n",
    "\n",
    "    # Display neural result\n",
    "    img_array2 = pred.reshape(rows,cols,3)\n",
    "    img_array2 = (img_array2*128)+128\n",
    "    img_array2 = img_array2.astype(np.uint8)\n",
    "    img2 = Image.fromarray(img_array2, 'RGB')\n",
    "    print(\"After auto encode noise removal\")\n",
    "    display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
